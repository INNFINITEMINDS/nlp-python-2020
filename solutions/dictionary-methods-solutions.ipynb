{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Basic dictionary methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Pre-processing\n",
    "\n",
    "First, read in our Music Reviews corpus as a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>release_date</th>\n",
       "      <th>critic</th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don't Panic</td>\n",
       "      <td>All Time Low</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2012-10-09 00:00:00</td>\n",
       "      <td>Kerrang!</td>\n",
       "      <td>74.0</td>\n",
       "      <td>While For Baltimore proves they can still writ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fear and Saturday Night</td>\n",
       "      <td>Ryan Bingham</td>\n",
       "      <td>Country</td>\n",
       "      <td>2015-01-20 00:00:00</td>\n",
       "      <td>Uncut</td>\n",
       "      <td>70.0</td>\n",
       "      <td>There's nothing fake about the purgatorial nar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Way I'm Livin'</td>\n",
       "      <td>Lee Ann Womack</td>\n",
       "      <td>Country</td>\n",
       "      <td>2014-09-23 00:00:00</td>\n",
       "      <td>Q Magazine</td>\n",
       "      <td>84.0</td>\n",
       "      <td>All life's disastrous lows are here on a caree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doris</td>\n",
       "      <td>Earl Sweatshirt</td>\n",
       "      <td>Rap</td>\n",
       "      <td>2013-08-20 00:00:00</td>\n",
       "      <td>Pitchfork</td>\n",
       "      <td>82.0</td>\n",
       "      <td>With Doris, Odd Future’s Odysseus is finally b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Giraffe</td>\n",
       "      <td>Echoboy</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2003-02-25 00:00:00</td>\n",
       "      <td>AllMusic</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Though Giraffe is definitely Echoboy's most im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Outer South</td>\n",
       "      <td>Conor Oberst And The Mystic Valley Band</td>\n",
       "      <td>Indie</td>\n",
       "      <td>2009-05-05 00:00:00</td>\n",
       "      <td>Slant Magazine</td>\n",
       "      <td>67.0</td>\n",
       "      <td>The result is an album that's unfortunately ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>On An Island</td>\n",
       "      <td>David Gilmour</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2006-03-07 00:00:00</td>\n",
       "      <td>E! Online</td>\n",
       "      <td>67.0</td>\n",
       "      <td>In the end, Island makes Dave sound like he's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Movement</td>\n",
       "      <td>Gossip</td>\n",
       "      <td>Indie</td>\n",
       "      <td>2003-05-06 00:00:00</td>\n",
       "      <td>Uncut</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Beth Ditto's remarkable gospel holler and ferv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Locked Down</td>\n",
       "      <td>Dr. John</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2012-04-03 00:00:00</td>\n",
       "      <td>PopMatters</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Dr. John is Dr. John. He's a star, and is on f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>And Their Refinement Of The Decline</td>\n",
       "      <td>Stars Of The Lid</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2007-04-07 00:00:00</td>\n",
       "      <td>PopMatters</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Their work, especially that displayed on Refin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5001 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    album  \\\n",
       "0                             Don't Panic   \n",
       "1                 Fear and Saturday Night   \n",
       "2                      The Way I'm Livin'   \n",
       "3                                   Doris   \n",
       "4                                 Giraffe   \n",
       "...                                   ...   \n",
       "4996                          Outer South   \n",
       "4997                         On An Island   \n",
       "4998                             Movement   \n",
       "4999                          Locked Down   \n",
       "5000  And Their Refinement Of The Decline   \n",
       "\n",
       "                                       artist     genre         release_date  \\\n",
       "0                                All Time Low  Pop/Rock  2012-10-09 00:00:00   \n",
       "1                                Ryan Bingham   Country  2015-01-20 00:00:00   \n",
       "2                              Lee Ann Womack   Country  2014-09-23 00:00:00   \n",
       "3                             Earl Sweatshirt       Rap  2013-08-20 00:00:00   \n",
       "4                                     Echoboy      Rock  2003-02-25 00:00:00   \n",
       "...                                       ...       ...                  ...   \n",
       "4996  Conor Oberst And The Mystic Valley Band     Indie  2009-05-05 00:00:00   \n",
       "4997                            David Gilmour      Rock  2006-03-07 00:00:00   \n",
       "4998                                   Gossip     Indie  2003-05-06 00:00:00   \n",
       "4999                                 Dr. John  Pop/Rock  2012-04-03 00:00:00   \n",
       "5000                         Stars Of The Lid      Rock  2007-04-07 00:00:00   \n",
       "\n",
       "              critic  score                                               body  \n",
       "0           Kerrang!   74.0  While For Baltimore proves they can still writ...  \n",
       "1              Uncut   70.0  There's nothing fake about the purgatorial nar...  \n",
       "2         Q Magazine   84.0  All life's disastrous lows are here on a caree...  \n",
       "3          Pitchfork   82.0  With Doris, Odd Future’s Odysseus is finally b...  \n",
       "4           AllMusic   71.0  Though Giraffe is definitely Echoboy's most im...  \n",
       "...              ...    ...                                                ...  \n",
       "4996  Slant Magazine   67.0  The result is an album that's unfortunately ba...  \n",
       "4997       E! Online   67.0  In the end, Island makes Dave sound like he's ...  \n",
       "4998           Uncut   81.0  Beth Ditto's remarkable gospel holler and ferv...  \n",
       "4999      PopMatters   86.0  Dr. John is Dr. John. He's a star, and is on f...  \n",
       "5000      PopMatters   87.0  Their work, especially that displayed on Refin...  \n",
       "\n",
       "[5001 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the necessary packages\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "\n",
    "#read the Music Reviews corpus into a Pandas dataframe\n",
    "df = pd.read_csv(\"../day-2/data/BDHSI2016_music_reviews.csv\", encoding='utf-8', sep = '\\t')\n",
    "\n",
    "#view the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create a new column in our dataset that contains tokenized words with all the pre-processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first create a new column called \"body_tokens\" and transform to lowercase by applying the string function str.lower()\n",
    "df['body'] = df['body'].apply(lambda x: ''.join([i for i in x if not i.isdigit()]))\n",
    "df['body_tokens'] = df['body'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize\n",
    "df['body_tokens'] = df['body_tokens'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = list(string.punctuation)\n",
    "\n",
    "#remove punctuation. Let's talk about that lambda x.\n",
    "df['body_tokens'] = df['body_tokens'].apply(lambda x: [word for word in x if word not in punctuations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token_count'] = df['body_tokens'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Creating dictionary counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sent = open(\"../day-2/data/positive_words.txt\", encoding='utf-8').read()\n",
    "neg_sent = open(\"../day-2/data/negative_words.txt\", encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remember the split function? We'll split on the newline character (\\n) to create a list\n",
    "positive_words=pos_sent.split('\\n')\n",
    "negative_words=neg_sent.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2231\n",
      "3906\n"
     ]
    }
   ],
   "source": [
    "#count number of words in each list\n",
    "print(len(positive_words))\n",
    "print(len(negative_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "1. Create a column with the number of positive words, and another with the proportion of positive words\n",
    "2. Create a column with the number of negative words, and another with the proportion of negative words\n",
    "3. Print the average proportion of negative and positive words by genre\n",
    "4. Compare this to the average score by genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>critic</th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "      <th>body_tokens</th>\n",
       "      <th>token_count</th>\n",
       "      <th>pos_num</th>\n",
       "      <th>neg_num</th>\n",
       "      <th>pos_prop</th>\n",
       "      <th>neg_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don't Panic</td>\n",
       "      <td>All Time Low</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>Kerrang!</td>\n",
       "      <td>74.0</td>\n",
       "      <td>While For Baltimore proves they can still writ...</td>\n",
       "      <td>[while, for, baltimore, proves, they, can, sti...</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fear and Saturday Night</td>\n",
       "      <td>Ryan Bingham</td>\n",
       "      <td>Country</td>\n",
       "      <td>Uncut</td>\n",
       "      <td>70.0</td>\n",
       "      <td>There's nothing fake about the purgatorial nar...</td>\n",
       "      <td>[there, 's, nothing, fake, about, the, purgato...</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Way I'm Livin'</td>\n",
       "      <td>Lee Ann Womack</td>\n",
       "      <td>Country</td>\n",
       "      <td>Q Magazine</td>\n",
       "      <td>84.0</td>\n",
       "      <td>All life's disastrous lows are here on a caree...</td>\n",
       "      <td>[all, life, 's, disastrous, lows, are, here, o...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doris</td>\n",
       "      <td>Earl Sweatshirt</td>\n",
       "      <td>Rap</td>\n",
       "      <td>Pitchfork</td>\n",
       "      <td>82.0</td>\n",
       "      <td>With Doris, Odd Future’s Odysseus is finally b...</td>\n",
       "      <td>[with, doris, odd, future, ’, s, odysseus, is,...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Giraffe</td>\n",
       "      <td>Echoboy</td>\n",
       "      <td>Rock</td>\n",
       "      <td>AllMusic</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Though Giraffe is definitely Echoboy's most im...</td>\n",
       "      <td>[though, giraffe, is, definitely, echoboy, 's,...</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.078431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Outer South</td>\n",
       "      <td>Conor Oberst And The Mystic Valley Band</td>\n",
       "      <td>Indie</td>\n",
       "      <td>Slant Magazine</td>\n",
       "      <td>67.0</td>\n",
       "      <td>The result is an album that's unfortunately ba...</td>\n",
       "      <td>[the, result, is, an, album, that, 's, unfortu...</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>On An Island</td>\n",
       "      <td>David Gilmour</td>\n",
       "      <td>Rock</td>\n",
       "      <td>E! Online</td>\n",
       "      <td>67.0</td>\n",
       "      <td>In the end, Island makes Dave sound like he's ...</td>\n",
       "      <td>[in, the, end, island, makes, dave, sound, lik...</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Movement</td>\n",
       "      <td>Gossip</td>\n",
       "      <td>Indie</td>\n",
       "      <td>Uncut</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Beth Ditto's remarkable gospel holler and ferv...</td>\n",
       "      <td>[beth, ditto, 's, remarkable, gospel, holler, ...</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Locked Down</td>\n",
       "      <td>Dr. John</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>PopMatters</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Dr. John is Dr. John. He's a star, and is on f...</td>\n",
       "      <td>[dr., john, is, dr., john, he, 's, a, star, an...</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>And Their Refinement Of The Decline</td>\n",
       "      <td>Stars Of The Lid</td>\n",
       "      <td>Rock</td>\n",
       "      <td>PopMatters</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Their work, especially that displayed on Refin...</td>\n",
       "      <td>[their, work, especially, that, displayed, on,...</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5001 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    album  \\\n",
       "0                             Don't Panic   \n",
       "1                 Fear and Saturday Night   \n",
       "2                      The Way I'm Livin'   \n",
       "3                                   Doris   \n",
       "4                                 Giraffe   \n",
       "...                                   ...   \n",
       "4996                          Outer South   \n",
       "4997                         On An Island   \n",
       "4998                             Movement   \n",
       "4999                          Locked Down   \n",
       "5000  And Their Refinement Of The Decline   \n",
       "\n",
       "                                       artist     genre          critic  \\\n",
       "0                                All Time Low  Pop/Rock        Kerrang!   \n",
       "1                                Ryan Bingham   Country           Uncut   \n",
       "2                              Lee Ann Womack   Country      Q Magazine   \n",
       "3                             Earl Sweatshirt       Rap       Pitchfork   \n",
       "4                                     Echoboy      Rock        AllMusic   \n",
       "...                                       ...       ...             ...   \n",
       "4996  Conor Oberst And The Mystic Valley Band     Indie  Slant Magazine   \n",
       "4997                            David Gilmour      Rock       E! Online   \n",
       "4998                                   Gossip     Indie           Uncut   \n",
       "4999                                 Dr. John  Pop/Rock      PopMatters   \n",
       "5000                         Stars Of The Lid      Rock      PopMatters   \n",
       "\n",
       "      score                                               body  \\\n",
       "0      74.0  While For Baltimore proves they can still writ...   \n",
       "1      70.0  There's nothing fake about the purgatorial nar...   \n",
       "2      84.0  All life's disastrous lows are here on a caree...   \n",
       "3      82.0  With Doris, Odd Future’s Odysseus is finally b...   \n",
       "4      71.0  Though Giraffe is definitely Echoboy's most im...   \n",
       "...     ...                                                ...   \n",
       "4996   67.0  The result is an album that's unfortunately ba...   \n",
       "4997   67.0  In the end, Island makes Dave sound like he's ...   \n",
       "4998   81.0  Beth Ditto's remarkable gospel holler and ferv...   \n",
       "4999   86.0  Dr. John is Dr. John. He's a star, and is on f...   \n",
       "5000   87.0  Their work, especially that displayed on Refin...   \n",
       "\n",
       "                                            body_tokens  token_count  pos_num  \\\n",
       "0     [while, for, baltimore, proves, they, can, sti...           38        1   \n",
       "1     [there, 's, nothing, fake, about, the, purgato...           28        0   \n",
       "2     [all, life, 's, disastrous, lows, are, here, o...           13        0   \n",
       "3     [with, doris, odd, future, ’, s, odysseus, is,...           18        0   \n",
       "4     [though, giraffe, is, definitely, echoboy, 's,...           51        2   \n",
       "...                                                 ...          ...      ...   \n",
       "4996  [the, result, is, an, album, that, 's, unfortu...           27        0   \n",
       "4997  [in, the, end, island, makes, dave, sound, lik...           17        3   \n",
       "4998  [beth, ditto, 's, remarkable, gospel, holler, ...           25        2   \n",
       "4999  [dr., john, is, dr., john, he, 's, a, star, an...           18        1   \n",
       "5000  [their, work, especially, that, displayed, on,...           28        5   \n",
       "\n",
       "      neg_num  pos_prop  neg_prop  \n",
       "0           0  0.026316  0.000000  \n",
       "1           3  0.000000  0.107143  \n",
       "2           1  0.000000  0.076923  \n",
       "3           1  0.000000  0.055556  \n",
       "4           4  0.039216  0.078431  \n",
       "...       ...       ...       ...  \n",
       "4996        3  0.000000  0.111111  \n",
       "4997        0  0.176471  0.000000  \n",
       "4998        0  0.080000  0.000000  \n",
       "4999        0  0.055556  0.000000  \n",
       "5000        0  0.178571  0.000000  \n",
       "\n",
       "[5001 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pos_num'] = df['body_tokens'].apply(lambda x: len([word for word in x if word in positive_words]))\n",
    "df['neg_num'] = df['body_tokens'].apply(lambda x: len([word for word in x if word in negative_words]))\n",
    "\n",
    "df['pos_prop'] = df['pos_num']/df['token_count']\n",
    "df['neg_prop'] = df['neg_num']/df['token_count']\n",
    "df.drop('release_date', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Folk                      0.096497\n",
       "Jazz                      0.087290\n",
       "Indie                     0.085293\n",
       "Alternative/Indie Rock    0.080572\n",
       "Rock                      0.080200\n",
       "Electronic                0.078628\n",
       "Dance                     0.078059\n",
       "Pop/Rock                  0.077627\n",
       "R&B;                      0.074498\n",
       "Country                   0.072140\n",
       "Rap                       0.070954\n",
       "Pop                       0.069679\n",
       "Name: pos_prop, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df.groupby('genre')\n",
    "grouped['pos_prop'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Jazz                      77.631579\n",
       "Folk                      75.900000\n",
       "Indie                     74.400897\n",
       "Country                   74.071429\n",
       "Alternative/Indie Rock    73.928571\n",
       "Electronic                73.140351\n",
       "Pop/Rock                  73.033782\n",
       "R&B;                      72.366071\n",
       "Rap                       72.173554\n",
       "Rock                      70.754292\n",
       "Dance                     70.146341\n",
       "Pop                       64.608054\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped['score'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3. Sentiment analysis using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the function CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "countvec = CountVectorizer()\n",
    "\n",
    "#create our document term matrix as a pandas dataframe\n",
    "dtm_df = pd.DataFrame(countvec.fit_transform(df.body).toarray(), columns=countvec.get_feature_names(), index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a columns variable that is a list of all column names\n",
    "columns = list(dtm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new variable that contains only column names that are in our postive words list\n",
    "pos_columns = [word for word in columns if word in positive_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dtm from our dtm_df that keeps only positive sentiment columns\n",
    "dtm_pos = dtm_df[pos_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-6c8dce3ade1d>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dtm_pos['pos_count'] = dtm_pos.sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "#count the number of positive words for each document\n",
    "dtm_pos['pos_count'] = dtm_pos.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "1. Do the same for negative words.  \n",
    "2. Calculate the proportion of negative and positive words for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-8529c9965bc9>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dtm_neg['neg_count'] = dtm_neg.sum(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       3\n",
       "2       1\n",
       "3       1\n",
       "4       4\n",
       "       ..\n",
       "4996    3\n",
       "4997    0\n",
       "4998    0\n",
       "4999    0\n",
       "5000    0\n",
       "Name: neg_count, Length: 5001, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_columns = [word for word in columns if word in negative_words]\n",
    "dtm_neg = dtm_df[neg_columns]\n",
    "\n",
    "dtm_neg['neg_count'] = dtm_neg.sum(axis=1)\n",
    "dtm_neg['neg_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.030303\n",
      "1       0.000000\n",
      "2       0.000000\n",
      "3       0.000000\n",
      "4       0.046512\n",
      "          ...   \n",
      "4996    0.000000\n",
      "4997    0.187500\n",
      "4998    0.095238\n",
      "4999    0.062500\n",
      "5000    0.178571\n",
      "Name: pos_proportion, Length: 5001, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-cafc0a53db4a>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dtm_pos['pos_proportion'] = dtm_pos['pos_count']/dtm_df.sum(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       0.026316\n",
       "1       0.000000\n",
       "2       0.000000\n",
       "3       0.000000\n",
       "4       0.039216\n",
       "          ...   \n",
       "4996    0.000000\n",
       "4997    0.176471\n",
       "4998    0.080000\n",
       "4999    0.055556\n",
       "5000    0.178571\n",
       "Name: pos_prop, Length: 5001, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_pos['pos_proportion'] = dtm_pos['pos_count']/dtm_df.sum(axis=1)\n",
    "print(dtm_pos['pos_proportion'])\n",
    "df['pos_prop']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Weighting dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read concreteness score dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "con_score = pd.read_csv('../day-2/data/Concreteness_ratings_Brysbaert_et_al.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the most concrete and most abstract words by sorting on `Conc.M`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Conc.M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>bat</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10689</th>\n",
       "      <td>eagle</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30740</th>\n",
       "      <td>shawl</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36046</th>\n",
       "      <td>umbrella</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>basket</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39703</th>\n",
       "      <td>would</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32378</th>\n",
       "      <td>spirituality</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>although</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10905</th>\n",
       "      <td>eh</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11618</th>\n",
       "      <td>essentialness</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39954 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word  Conc.M\n",
       "2547             bat    5.00\n",
       "10689          eagle    5.00\n",
       "30740          shawl    5.00\n",
       "36046       umbrella    5.00\n",
       "2526          basket    5.00\n",
       "...              ...     ...\n",
       "39703          would    1.12\n",
       "32378   spirituality    1.07\n",
       "941         although    1.07\n",
       "10905             eh    1.04\n",
       "11618  essentialness    1.04\n",
       "\n",
       "[39954 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_score[['Word','Conc.M']].sort_values(by='Conc.M',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Conc.M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10905</th>\n",
       "      <td>eh</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11618</th>\n",
       "      <td>essentialness</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32378</th>\n",
       "      <td>spirituality</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>although</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39703</th>\n",
       "      <td>would</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25452</th>\n",
       "      <td>pick-up truck</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6160</th>\n",
       "      <td>comb</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6476</th>\n",
       "      <td>computer mouse</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7132</th>\n",
       "      <td>cookie</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37017</th>\n",
       "      <td>unicycle</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39954 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Word  Conc.M\n",
       "10905              eh    1.04\n",
       "11618   essentialness    1.04\n",
       "32378    spirituality    1.07\n",
       "941          although    1.07\n",
       "39703           would    1.12\n",
       "...               ...     ...\n",
       "25452   pick-up truck    5.00\n",
       "6160             comb    5.00\n",
       "6476   computer mouse    5.00\n",
       "7132           cookie    5.00\n",
       "37017        unicycle    5.00\n",
       "\n",
       "[39954 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_score[['Word','Conc.M']].sort_values(by='Conc.M',ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Merging a DTM with a weighted dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = []\n",
    "#open and read the novels, save them as variables\n",
    "austen_string = open('../day-2/data/Austen_PrideAndPrejudice.txt', encoding='utf-8').read()\n",
    "alcott_string = open('../day-2/data/Alcott_GarlandForGirls.txt', encoding='utf-8').read()\n",
    "\n",
    "#append each novel to the list\n",
    "text_list.append(austen_string)\n",
    "text_list.append(alcott_string)\n",
    "\n",
    "countvec = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "novels_df = pd.DataFrame(countvec.fit_transform(text_list).toarray(), columns=countvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll take a subset of the DTM, keeping only the intersection between the words in our corpus and the word in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=list(novels_df)\n",
    "columns_con = [word for word in columns if word in list(con_score['Word'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "novels_df_con = novels_df[columns_con]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, transpose the matrix, rename the column, and merge with the dictionary dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = novels_df_con.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={0: 'Austen', 1: 'Alcott'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the index 'Word', and reset the index, so the words become a column in our dataframe and we get a new index.\n",
    "df.index.names = ['Word']\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with our dictionary dataframe, called 'con_score'\n",
    "df = df.merge(con_score, on = 'Word')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Weighting term frequencies by the concreteness score\n",
    "\n",
    "Now we can weight the term frquency cells by the concreteness score, by multiplying the frequency count column by the concreteness score column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['austen_con_score'] = df['Austen'] * df['Conc.M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alcott_con_score'] = df['Alcott'] * df['Conc.M']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Calculate and print the average concreteness score for each text. Careful! Think through this before you implement it. You want the average score, normalized over all the words in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Concreteness for Austen's 'Pride and Prejudice'\n",
      "2.783289058278108\n",
      "\n",
      "Mean Concreteness for Alcott's 'A Garland for Girls'\n",
      "3.1534507874015745\n"
     ]
    }
   ],
   "source": [
    "#we'll devide the sum of the concreteness score by the total word count for each novel\n",
    "print(\"Mean Concreteness for Austen's 'Pride and Prejudice'\")\n",
    "print(df['austen_con_score'].sum()/df['Austen'].sum())\n",
    "print()\n",
    "print(\"Mean Concreteness for Alcott's 'A Garland for Girls'\")\n",
    "print(df['alcott_con_score'].sum()/df['Alcott'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Assessing the difference\n",
    "\n",
    "So there is a difference, but what does it mean? What is the magnitude of the difference?\n",
    "\n",
    "We can look at the difference between the two means as a percent difference based on the scale range. We can calculate this using simple math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37016172912000034"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first find the difference between the means by substracting one from the other\n",
    "3.1534507874-2.78328905828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "#Find the range of concreteness scores\n",
    "print(df['Conc.M'].min())\n",
    "print(df['Conc.M'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.83"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The scale range\n",
    "df['Conc.M'].max() - df['Conc.M'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.660574412532636"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the difference of means as a percent of this range\n",
    "(0.37/3.83)* 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "Print the most concrete and abstract terms in Austen and in Alcott.  \n",
    "*Hint:* You can't simply sort on the column `austen_con_score` and so on. Why not? What are your next steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Alcott</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>house</td>\n",
       "      <td>5.00</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6033</th>\n",
       "      <td>water</td>\n",
       "      <td>5.00</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>bed</td>\n",
       "      <td>5.00</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>boots</td>\n",
       "      <td>5.00</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>fish</td>\n",
       "      <td>5.00</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>especially</td>\n",
       "      <td>1.28</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5094</th>\n",
       "      <td>somewhat</td>\n",
       "      <td>1.28</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705</th>\n",
       "      <td>sanctimonious</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>hope</td>\n",
       "      <td>1.25</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>whatsoever</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4262 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word  Conc.M  Alcott\n",
       "2692          house    5.00      65\n",
       "6033          water    5.00      32\n",
       "470             bed    5.00      25\n",
       "590           boots    5.00      17\n",
       "2139           fish    5.00      17\n",
       "...             ...     ...     ...\n",
       "1891     especially    1.28      12\n",
       "5094       somewhat    1.28       5\n",
       "4705  sanctimonious    1.28       1\n",
       "2671           hope    1.25      40\n",
       "6080     whatsoever    1.17       1\n",
       "\n",
       "[4262 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new dataframe that keeps only words that have a non-zero value in Alcott\n",
    "df_alcott = df[df['Alcott']>0]\n",
    "#Sort on 'Conc.M' and pring in descending order for most concrete words\n",
    "df_alcott[['Word', 'Conc.M', 'Alcott']].sort_values(by=['Conc.M', 'Alcott'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Austen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>house</td>\n",
       "      <td>5.00</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>ball</td>\n",
       "      <td>5.00</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>stairs</td>\n",
       "      <td>5.00</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>bed</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>clock</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>hope</td>\n",
       "      <td>1.25</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>absurdity</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>advantageously</td>\n",
       "      <td>1.24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>infinitely</td>\n",
       "      <td>1.22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>belief</td>\n",
       "      <td>1.19</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4070 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word  Conc.M  Austen\n",
       "2692           house    5.00     108\n",
       "413             ball    5.00      36\n",
       "5198          stairs    5.00      24\n",
       "470              bed    5.00       6\n",
       "921            clock    5.00       6\n",
       "...              ...     ...     ...\n",
       "2671            hope    1.25     121\n",
       "23         absurdity    1.25       1\n",
       "109   advantageously    1.24       2\n",
       "2873      infinitely    1.22       4\n",
       "490           belief    1.19      15\n",
       "\n",
       "[4070 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new dataframe that keeps only words that have a non-zero value in Austen\n",
    "df_austen = df[df['Austen']>0]\n",
    "df_austen[['Word', 'Conc.M', 'Austen']].sort_values(by=['Conc.M', 'Austen'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Weighting words with TF-IDF<a id='tfidf'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use our Music Reviews corpus for this. Read into Pandas DataFrame:\n",
    "df = pd.read_csv(\"../day-2/data/BDHSI2016_music_reviews.csv\", encoding='utf-8', sep = '\\t')\n",
    "\n",
    "# Clean out numbers:\n",
    "df['body'] = df['body'].apply(lambda x: ''.join([i for i in x if not i.isdigit()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aahs</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abc</th>\n",
       "      <th>...</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zooey</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zu</th>\n",
       "      <th>zydeco</th>\n",
       "      <th>álbum</th>\n",
       "      <th>être</th>\n",
       "      <th>über</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5001 rows × 16139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaaa  aahs  aaliyah  aaron   ab  abandon  abandoned  abandoning  \\\n",
       "0     0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0   \n",
       "1     0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0   \n",
       "2     0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0   \n",
       "3     0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0   \n",
       "4     0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0   \n",
       "...   ...   ...   ...      ...    ...  ...      ...        ...         ...   \n",
       "4996  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0   \n",
       "4997  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0   \n",
       "4998  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0   \n",
       "4999  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0   \n",
       "5000  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0   \n",
       "\n",
       "      abc  ...  zone  zones  zoo  zooey  zoomer   zu  zydeco  álbum  être  \\\n",
       "0     0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   \n",
       "1     0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   \n",
       "2     0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   \n",
       "3     0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   \n",
       "4     0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   \n",
       "...   ...  ...   ...    ...  ...    ...     ...  ...     ...    ...   ...   \n",
       "4996  0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   \n",
       "4997  0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   \n",
       "4998  0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   \n",
       "4999  0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   \n",
       "5000  0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   \n",
       "\n",
       "      über  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "...    ...  \n",
       "4996   0.0  \n",
       "4997   0.0  \n",
       "4998   0.0  \n",
       "4999   0.0  \n",
       "5000   0.0  \n",
       "\n",
       "[5001 rows x 16139 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the function TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidfvec = TfidfVectorizer()\n",
    "\n",
    "#create the dtm, but with cells weigthed by the tf-idf score.\n",
    "tfidf_df = pd.DataFrame(tfidfvec.fit_transform(df['body']).toarray(), columns=tfidfvec.get_feature_names())\n",
    "\n",
    "#view results\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Distinctive Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat dataset with document index and genre\n",
    "df_genre = df['genre'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge this into the dtm_tfidf_df\n",
    "merged_df = df_genre.join(tfidf_df, how = 'right', lsuffix='_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rap Words\n",
      "<bound method DataFrame.max of      genre_x   aa  aaaa  aahs  aaliyah  aaron   ab  abandon  abandoned  \\\n",
      "3        Rap  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0   \n",
      "18       Rap  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0   \n",
      "24       Rap  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0   \n",
      "33       Rap  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0   \n",
      "42       Rap  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0   \n",
      "...      ...  ...   ...   ...      ...    ...  ...      ...        ...   \n",
      "4958     Rap  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0   \n",
      "4960     Rap  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0   \n",
      "4964     Rap  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0   \n",
      "4991     Rap  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0   \n",
      "4995     Rap  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0   \n",
      "\n",
      "      abandoning  ...  zone  zones  zoo  zooey  zoomer   zu  zydeco  álbum  \\\n",
      "3            0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   \n",
      "18           0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   \n",
      "24           0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   \n",
      "33           0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   \n",
      "42           0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   \n",
      "...          ...  ...   ...    ...  ...    ...     ...  ...     ...    ...   \n",
      "4958         0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   \n",
      "4960         0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   \n",
      "4964         0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   \n",
      "4991         0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   \n",
      "4995         0.0  ...   0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   \n",
      "\n",
      "      être  über  \n",
      "3      0.0   0.0  \n",
      "18     0.0   0.0  \n",
      "24     0.0   0.0  \n",
      "33     0.0   0.0  \n",
      "42     0.0   0.0  \n",
      "...    ...   ...  \n",
      "4958   0.0   0.0  \n",
      "4960   0.0   0.0  \n",
      "4964   0.0   0.0  \n",
      "4991   0.0   0.0  \n",
      "4995   0.0   0.0  \n",
      "\n",
      "[363 rows x 16140 columns]>\n"
     ]
    }
   ],
   "source": [
    "#pull out the reviews for three genres, Rap, Alternative/Indie Rock, and Jazz\n",
    "dtm_rap = merged_df[merged_df['genre_x']==\"Rap\"]\n",
    "dtm_indie = merged_df[merged_df['genre_x']==\"Alternative/Indie Rock\"]\n",
    "dtm_jazz = merged_df[merged_df['genre_x']==\"Jazz\"]\n",
    "\n",
    "#print the words with the highest tf-idf scores for each genre\n",
    "print(\"Rap Words\")\n",
    "print(dtm_rap.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Compare the distinctive words for two artists in the data.\n",
    "\n",
    "Note: the artists should have a number of reviews, so check your frequency counts to identify artists.\n",
    "\n",
    "HINT: Copy and paste the above code and modify it as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REM\n",
      "reliably        0.579442\n",
      "staid           0.550549\n",
      "every           0.530261\n",
      "isn             0.523994\n",
      "unfussy         0.513744\n",
      "crucially       0.459618\n",
      "committed       0.434459\n",
      "convincing      0.434459\n",
      "fast            0.424265\n",
      "collapse        0.421777\n",
      "habit           0.410508\n",
      "accelerate      0.410508\n",
      "stun            0.391646\n",
      "forming         0.391646\n",
      "dec             0.376505\n",
      "noncommittal    0.368986\n",
      "beautiful       0.358367\n",
      "mostly          0.352703\n",
      "stutter         0.352486\n",
      "stipe           0.352032\n",
      "dtype: float64\n",
      "\n",
      "Arcade Fire\n",
      "disc           0.459815\n",
      "reflektor      0.431429\n",
      "jumping        0.423503\n",
      "patterns       0.409032\n",
      "features       0.408639\n",
      "bitterness     0.408519\n",
      "shorter        0.397541\n",
      "radiates       0.389749\n",
      "affection      0.389749\n",
      "suburbs        0.377718\n",
      "beguiling      0.374164\n",
      "detox          0.373836\n",
      "components     0.364664\n",
      "divergence     0.363223\n",
      "redeem         0.356659\n",
      "paced          0.352743\n",
      "letter         0.350524\n",
      "divergent      0.345035\n",
      "double         0.336293\n",
      "proposition    0.336020\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_artist = df['artist'].to_frame()\n",
    "merged_df_artist = df_artist.join(tfidf_df, how = 'right', lsuffix='_x')\n",
    "\n",
    "#view result\n",
    "\n",
    "dtm1 = merged_df_artist[merged_df_artist['artist_x']==\"R.E.M.\"]\n",
    "dtm2 = merged_df_artist[merged_df_artist['artist_x']==\"Arcade Fire\"]\n",
    "print(\"REM\")\n",
    "print(dtm1.max(numeric_only=True).sort_values(ascending=False)[0:20])\n",
    "print()\n",
    "print(\"Arcade Fire\")\n",
    "print(dtm2.max(numeric_only=True).sort_values(ascending=False)[0:20])\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary Methods\n",
    "\n",
    "This is the most simple way to measure the prevalence of a theme in a corpus, and is used for many purposes, including sentiment analysis. This is one of the most long-standing, and ubiquitous, methods in automated text analysis, so it's important to both understand the method and be able to implement it.\n",
    "\n",
    "The method is simple: it involves grouping words into categories or themes, and then counting the number of words from each theme's word list (or dictionary) in your corpus. We will use this method to do sentiment analysis, a popular text analysis task, on a corpus of Music Reviews, using a standard sentiment analysis dictionary.\n",
    "\n",
    "## Learning Goals\n",
    "* Understand the intuition behind dictionary methods\n",
    "* Learn how to implement in via Python Pandas and NLTK\n",
    "* Get more comfortable combining Python packages together\n",
    "* Implement a rudimentary sentiment analysis tool and test it on sample data\n",
    "* Practice applying a weighted dictionary\n",
    "\n",
    "\n",
    "## Outline\n",
    "(TO DO: Add links for each section)\n",
    "* Part 0: Basic dictionary method\n",
    "    0. Introduction to dictionary methods\n",
    "        * Standard dictionaries\n",
    "        * Custom dictionaries\n",
    "    1. Pre-processing\n",
    "    2. Creating dictionary counts\n",
    "    3. Sentiment analysis using Scikit-learn\n",
    "* Part 1: Weighted dictionary\n",
    "    0. Read concreteness score dictionary\n",
    "    1. Merging a DTM with a weighted dictionary\n",
    "    2. Weight term frequencies by their concreteness score\n",
    "    3. Calculating an average concreteness score for each text\n",
    "    4. Assess the difference\n",
    "\n",
    "## Vocabulary\n",
    "\n",
    "* *dictionary method*:\n",
    "    * text analysis method that utilizes the frequency of key words, grouped into themes, to determine the prevelance of that theme throughout a corpus.\n",
    "* *standard dictionary*:\n",
    "    * otherwise known as general dictionaries, a dictionary created by experts meant to measure general phenomenon.\n",
    "* *custom dictionary*:\n",
    "    * dictionaries tailored to a specific domain or question. Usually created by the researcher based on the research question.\n",
    "* *sentiment analysis*:\n",
    "    * the process of computationally identifying and categorizing opinions expressed in a piece of text, especially in order to determine whether the writer's attitude towards a particular topic, product, etc., is positive, negative, or neutral.\n",
    "    \n",
    "## Further Resources\n",
    "\n",
    "TO DO: Edit these resources (consider deleting)\n",
    "\n",
    "[A Novel Method for Detecting Plot](http://www.matthewjockers.net/2014/06/05/a-novel-method-for-detecting-plot/), Matt Jockers\n",
    "\n",
    "Enns, Peter, Nathan Kelly, Jana Morgan, and Christopher Witko. 2015.[“Money and the Supply\n",
    "of Political Rhetoric: Understanding the Congressional (Non-)Response to Economic Inequality.”](http://cdn.equitablegrowth.org/wp-content/uploads/2016/06/29155322/enns-kelly-morgan-witko-econinterests-policyagenda.pdf) Paper presented at the APSA Annual Meetings, San Francisco.\n",
    "* Outlines the process of creating your own dictionary\n",
    "\n",
    "[Neal Caren has a tutorial using MPQA](http://nealcaren.web.unc.edu/an-introduction-to-text-analysis-with-python-part-3/), which implements the dictionary method in Python but in a much different way \n",
    "\n",
    "**__________________________________**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Basic dictionary methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0 Introduction to dictionary methods\n",
    "\n",
    "The basic idea behind dictionary methods is that language reflects social position and culture: the cognitive categories through which individuals attend to the world are embedded in the words they use.  Words that are used frequently are cognitively central and reflect what is most on the speaker’s (or writer’s) mind.  Words that are used infrequently or not at all are at the speaker’s cognitive periphery, perhaps even representing uncomfortable or alien concepts.\n",
    "\n",
    "More practically, dictionary methods are based on the assumption that themes or categories consist of a group of words, and texts that cover that theme will have a higher percentage of that group of words compared to other texts. Dictionary-based analysis is appropriate when the categories and the textual features (words and/or phrases associated with each category) are known and fixed--based on expert knowledge, crowd-sourcing, etc. \n",
    "\n",
    "Dictionary methods are used for many purposes. A few possibilities:\n",
    "* classify text into themes\n",
    "* measure the *tone* of text\n",
    "* measure sentiment\n",
    "* measure psychological processes\n",
    "\n",
    "There are two forms of dictionaries: standard or general dictionaries, and custom dictionaries.\n",
    "\n",
    "### Standard dictionaries\n",
    "\n",
    "There are a number of standard dictionaries that have been created by field experts. The benefit of standarized dictionaries is that they're developed by experts and have been throughoughly validated. Others have likely published using these dictionaries, so reviewers are more likely to accept them as valid. Because of this, they are good options if they fit your research question.\n",
    "\n",
    "Here are a few:\n",
    "\n",
    "* [DICTION](http://www.dictionsoftware.com/): a computer-aided text analysis program for determining the tone of a text. It was created by and for organization scholars and political scientists.\n",
    "    * Main five categories: Certainty, Activity, Optimism, Realism, Commonality\n",
    "    * 35 sub-categories\n",
    "    * Allows you to create your own dictionary\n",
    "    * Proprietary software\n",
    "* [Linguistic Inquiry and Word Count (LIWC)](http://liwc.wpengine.com/): Created by psychologists, it's meant to capture psychological processes around feelings, personality, and motivations. It's also proprietary.\n",
    "* [Multi-Perspective Question Answering (MPQA)](http://mpqa.cs.pitt.edu/): The free version of LIWC. We will use this dictionary today.\n",
    "* [Valence Aware Dictionary and sEntiment Reasoner (VADER)](https://github.com/cjhutto/vaderSentiment): a popular and free rule-based sentiment analysis tool tuned to capture sentiment in social media data.\n",
    "* [Harvard General Inquirer](http://www.wjh.harvard.edu/~inquirer/spreadsheet_guide.htm). Multiple categories, including abstract and concrete words. It's free and available online.\n",
    "\n",
    "However, dictionaries are context-specific, and applying a dictionary outside its original target domain can lead to serious problems. A classic example was applying the Harvard General Inquirer to classify negative tone in corporate earnings reports--which [leads to serious problems](https://onlinelibrary.wiley.com/doi/full/10.1111/j.1540-6261.2010.01625.x?casa_token=Vl0Os0QtDIQAAAAA%3AaxNRNAj4ajoocjLv_DCJMsS8GEA_jAqb_Z26h5I8g1yW0muShiPs_lglFbpHR-3AU1etsuyjhdN_ahZy). For example, the term \"vice\" characterizes an executive rather than immorality, while \"tire\" is not negative in the context of automobile industry reports. And some negative words aren't captured at all: the terms \"litigation\" and \"unanticipated\" are missing from the Harvard list. Enough of these problems means the results of our analyses will be wrong. So sometimes it's worth the effort to create a custom dictionary.\n",
    "\n",
    "### Custom dictionaries\n",
    "\n",
    "Many research questions or data are domain specific, however, and will thus require you to create your own dictionary based on your own knowledge of the domain and question. Creating your own dictionary requires a lot of thought, and must be validated. These dictionaries are typically created in an interative fashion, and are modified as they are validated. See Enns et al. (2015) or Haber (2020) for examples of how to construct a domain-specific dictionary. \n",
    "\n",
    "Today we will use the free and standard sentiment dictionary from MPQA (or VADER?) to measure positive and negative sentiment in the music reviews.\n",
    "\n",
    "Our first step, as with any technique, is the pre-processing step, to get the data ready for analyis.\n",
    "\n",
    "## 0.1 Pre-processing\n",
    "\n",
    "First, read in our Music Reviews corpus as a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>release_date</th>\n",
       "      <th>critic</th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don't Panic</td>\n",
       "      <td>All Time Low</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2012-10-09 00:00:00</td>\n",
       "      <td>Kerrang!</td>\n",
       "      <td>74.0</td>\n",
       "      <td>While For Baltimore proves they can still writ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fear and Saturday Night</td>\n",
       "      <td>Ryan Bingham</td>\n",
       "      <td>Country</td>\n",
       "      <td>2015-01-20 00:00:00</td>\n",
       "      <td>Uncut</td>\n",
       "      <td>70.0</td>\n",
       "      <td>There's nothing fake about the purgatorial nar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Way I'm Livin'</td>\n",
       "      <td>Lee Ann Womack</td>\n",
       "      <td>Country</td>\n",
       "      <td>2014-09-23 00:00:00</td>\n",
       "      <td>Q Magazine</td>\n",
       "      <td>84.0</td>\n",
       "      <td>All life's disastrous lows are here on a caree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doris</td>\n",
       "      <td>Earl Sweatshirt</td>\n",
       "      <td>Rap</td>\n",
       "      <td>2013-08-20 00:00:00</td>\n",
       "      <td>Pitchfork</td>\n",
       "      <td>82.0</td>\n",
       "      <td>With Doris, Odd Future’s Odysseus is finally b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Giraffe</td>\n",
       "      <td>Echoboy</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2003-02-25 00:00:00</td>\n",
       "      <td>AllMusic</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Though Giraffe is definitely Echoboy's most im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Outer South</td>\n",
       "      <td>Conor Oberst And The Mystic Valley Band</td>\n",
       "      <td>Indie</td>\n",
       "      <td>2009-05-05 00:00:00</td>\n",
       "      <td>Slant Magazine</td>\n",
       "      <td>67.0</td>\n",
       "      <td>The result is an album that's unfortunately ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>On An Island</td>\n",
       "      <td>David Gilmour</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2006-03-07 00:00:00</td>\n",
       "      <td>E! Online</td>\n",
       "      <td>67.0</td>\n",
       "      <td>In the end, Island makes Dave sound like he's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Movement</td>\n",
       "      <td>Gossip</td>\n",
       "      <td>Indie</td>\n",
       "      <td>2003-05-06 00:00:00</td>\n",
       "      <td>Uncut</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Beth Ditto's remarkable gospel holler and ferv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Locked Down</td>\n",
       "      <td>Dr. John</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2012-04-03 00:00:00</td>\n",
       "      <td>PopMatters</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Dr. John is Dr. John. He's a star, and is on f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>And Their Refinement Of The Decline</td>\n",
       "      <td>Stars Of The Lid</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2007-04-07 00:00:00</td>\n",
       "      <td>PopMatters</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Their work, especially that displayed on Refin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5001 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    album  \\\n",
       "0                             Don't Panic   \n",
       "1                 Fear and Saturday Night   \n",
       "2                      The Way I'm Livin'   \n",
       "3                                   Doris   \n",
       "4                                 Giraffe   \n",
       "...                                   ...   \n",
       "4996                          Outer South   \n",
       "4997                         On An Island   \n",
       "4998                             Movement   \n",
       "4999                          Locked Down   \n",
       "5000  And Their Refinement Of The Decline   \n",
       "\n",
       "                                       artist     genre         release_date  \\\n",
       "0                                All Time Low  Pop/Rock  2012-10-09 00:00:00   \n",
       "1                                Ryan Bingham   Country  2015-01-20 00:00:00   \n",
       "2                              Lee Ann Womack   Country  2014-09-23 00:00:00   \n",
       "3                             Earl Sweatshirt       Rap  2013-08-20 00:00:00   \n",
       "4                                     Echoboy      Rock  2003-02-25 00:00:00   \n",
       "...                                       ...       ...                  ...   \n",
       "4996  Conor Oberst And The Mystic Valley Band     Indie  2009-05-05 00:00:00   \n",
       "4997                            David Gilmour      Rock  2006-03-07 00:00:00   \n",
       "4998                                   Gossip     Indie  2003-05-06 00:00:00   \n",
       "4999                                 Dr. John  Pop/Rock  2012-04-03 00:00:00   \n",
       "5000                         Stars Of The Lid      Rock  2007-04-07 00:00:00   \n",
       "\n",
       "              critic  score                                               body  \n",
       "0           Kerrang!   74.0  While For Baltimore proves they can still writ...  \n",
       "1              Uncut   70.0  There's nothing fake about the purgatorial nar...  \n",
       "2         Q Magazine   84.0  All life's disastrous lows are here on a caree...  \n",
       "3          Pitchfork   82.0  With Doris, Odd Future’s Odysseus is finally b...  \n",
       "4           AllMusic   71.0  Though Giraffe is definitely Echoboy's most im...  \n",
       "...              ...    ...                                                ...  \n",
       "4996  Slant Magazine   67.0  The result is an album that's unfortunately ba...  \n",
       "4997       E! Online   67.0  In the end, Island makes Dave sound like he's ...  \n",
       "4998           Uncut   81.0  Beth Ditto's remarkable gospel holler and ferv...  \n",
       "4999      PopMatters   86.0  Dr. John is Dr. John. He's a star, and is on f...  \n",
       "5000      PopMatters   87.0  Their work, especially that displayed on Refin...  \n",
       "\n",
       "[5001 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the necessary packages\n",
    "import pandas\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "\n",
    "#read the Music Reviews corpus into a Pandas dataframe\n",
    "df = pandas.read_csv(\"../day-2/data/BDHSI2016_music_reviews.csv\", encoding='utf-8', sep = '\\t')\n",
    "\n",
    "#view the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create a new column in our dataset that contains tokenized words with all the pre-processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first create a new column called \"body_tokens\" and transform to lowercase by applying the string function str.lower()\n",
    "df['body'] = df['body'].apply(lambda x: ''.join([i for i in x if not i.isdigit()]))\n",
    "df['body_tokens'] = df['body'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [while, for, baltimore, proves, they, can, sti...\n",
      "1       [there, 's, nothing, fake, about, the, purgato...\n",
      "2       [all, life, 's, disastrous, lows, are, here, o...\n",
      "3       [with, doris, ,, odd, future, ’, s, odysseus, ...\n",
      "4       [though, giraffe, is, definitely, echoboy, 's,...\n",
      "                              ...                        \n",
      "4996    [the, result, is, an, album, that, 's, unfortu...\n",
      "4997    [in, the, end, ,, island, makes, dave, sound, ...\n",
      "4998    [beth, ditto, 's, remarkable, gospel, holler, ...\n",
      "4999    [dr., john, is, dr., john, ., he, 's, a, star,...\n",
      "5000    [their, work, ,, especially, that, displayed, ...\n",
      "Name: body_tokens, Length: 5001, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#tokenize\n",
    "df['body_tokens'] = df['body_tokens'].apply(nltk.word_tokenize)\n",
    "\n",
    "#view output\n",
    "print(df['body_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [while, for, baltimore, proves, they, can, sti...\n",
      "1       [there, 's, nothing, fake, about, the, purgato...\n",
      "2       [all, life, 's, disastrous, lows, are, here, o...\n",
      "3       [with, doris, odd, future, ’, s, odysseus, is,...\n",
      "4       [though, giraffe, is, definitely, echoboy, 's,...\n",
      "                              ...                        \n",
      "4996    [the, result, is, an, album, that, 's, unfortu...\n",
      "4997    [in, the, end, island, makes, dave, sound, lik...\n",
      "4998    [beth, ditto, 's, remarkable, gospel, holler, ...\n",
      "4999    [dr., john, is, dr., john, he, 's, a, star, an...\n",
      "5000    [their, work, especially, that, displayed, on,...\n",
      "Name: body_tokens, Length: 5001, dtype: object\n"
     ]
    }
   ],
   "source": [
    "punctuations = list(string.punctuation)\n",
    "\n",
    "#remove punctuation. Let's talk about that lambda x.\n",
    "df['body_tokens'] = df['body_tokens'].apply(lambda x: [word for word in x if word not in punctuations])\n",
    "\n",
    "#view output\n",
    "print(df['body_tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing is done. What other pre-processing steps might we use?\n",
    "\n",
    "One more step before getting to the dictionary method. We want a total token count for each row, so we can normalize the dictionary counts. To do this we simply create a new column that contains the length of the token list in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            body_tokens  token_count\n",
      "0     [while, for, baltimore, proves, they, can, sti...           38\n",
      "1     [there, 's, nothing, fake, about, the, purgato...           28\n",
      "2     [all, life, 's, disastrous, lows, are, here, o...           13\n",
      "3     [with, doris, odd, future, ’, s, odysseus, is,...           18\n",
      "4     [though, giraffe, is, definitely, echoboy, 's,...           51\n",
      "...                                                 ...          ...\n",
      "4996  [the, result, is, an, album, that, 's, unfortu...           27\n",
      "4997  [in, the, end, island, makes, dave, sound, lik...           17\n",
      "4998  [beth, ditto, 's, remarkable, gospel, holler, ...           25\n",
      "4999  [dr., john, is, dr., john, he, 's, a, star, an...           18\n",
      "5000  [their, work, especially, that, displayed, on,...           28\n",
      "\n",
      "[5001 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df['token_count'] = df['body_tokens'].apply(lambda x: len(x))\n",
    "\n",
    "print(df[['body_tokens','token_count']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Creating dictionary counts\n",
    "\n",
    "I created two text files, one is a list of positive words from the MPQA dictionary, the other is a list of negative words. One word per line. Our goal here is to count the number of positive and negative words in each row of our dataframe, and add two columns to our dataset with the count of positive and negative words.\n",
    "\n",
    "First, read in the positive and negative words and create list variables for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abidance\n",
      "abidance\n",
      "abilities\n",
      "ability\n",
      "able\n",
      "above\n",
      "above-average\n",
      "abundant\n",
      "abundance\n",
      "acceptance\n",
      "acceptable\n"
     ]
    }
   ],
   "source": [
    "pos_sent = open(\"../day-2/data/positive_words.txt\", encoding='utf-8').read()\n",
    "neg_sent = open(\"../day-2/data/negative_words.txt\", encoding='utf-8').read()\n",
    "\n",
    "#view part of the pos_sent variable, to see how it's formatted.\n",
    "print(pos_sent[:101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abidance', 'abidance', 'abilities', 'ability', 'able', 'above', 'above-average', 'abundant', 'abundance', 'acceptance']\n",
      "['abandoned', 'abandonment', 'aberration', 'aberration', 'abhorred', 'abhorrence', 'abhorrent', 'abhorrently', 'abhors', 'abhors']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['abidance',\n",
       " 'abidance',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'above',\n",
       " 'above-average',\n",
       " 'abundant',\n",
       " 'abundance',\n",
       " 'acceptance',\n",
       " 'acceptable',\n",
       " 'accessible',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'accolade',\n",
       " 'accolades',\n",
       " 'accommodative',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accordance',\n",
       " 'accordantly',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'achievable',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'acknowledgement',\n",
       " 'active',\n",
       " 'acumen',\n",
       " 'adaptable',\n",
       " 'adaptability',\n",
       " 'adaptive',\n",
       " 'adept',\n",
       " 'adeptly',\n",
       " 'adequate',\n",
       " 'adherence',\n",
       " 'adherent',\n",
       " 'adhesion',\n",
       " 'admirable',\n",
       " 'admirer',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiration',\n",
       " 'admiring',\n",
       " 'admiringly',\n",
       " 'admission',\n",
       " 'admission',\n",
       " 'adorable',\n",
       " 'adored',\n",
       " 'adorer',\n",
       " 'adoring',\n",
       " 'adoringly',\n",
       " 'adroit',\n",
       " 'adroitly',\n",
       " 'adulatory',\n",
       " 'advanced',\n",
       " 'advantage',\n",
       " 'advantage',\n",
       " 'advantageous',\n",
       " 'advantages',\n",
       " 'advantages',\n",
       " 'adventure',\n",
       " 'adventure',\n",
       " 'adventuresome',\n",
       " 'adventurism',\n",
       " 'adventurous',\n",
       " 'advice',\n",
       " 'advice',\n",
       " 'advisable',\n",
       " 'advocacy',\n",
       " 'affable',\n",
       " 'affability',\n",
       " 'affably',\n",
       " 'affection',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affinity',\n",
       " 'affirmation',\n",
       " 'affirmation',\n",
       " 'affirmative',\n",
       " 'affluent',\n",
       " 'affluence',\n",
       " 'affordable',\n",
       " 'afloat',\n",
       " 'agile',\n",
       " 'agilely',\n",
       " 'agility',\n",
       " 'agreeable',\n",
       " 'agreement',\n",
       " 'agreement',\n",
       " 'allowable',\n",
       " 'allure',\n",
       " 'alluring',\n",
       " 'alluringly',\n",
       " 'almighty',\n",
       " 'altruist',\n",
       " 'altruistic',\n",
       " 'altruistically',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'ambitious',\n",
       " 'ambitious',\n",
       " 'amenable',\n",
       " 'amenity',\n",
       " 'amiability',\n",
       " 'amiabily',\n",
       " 'amiable',\n",
       " 'amicability',\n",
       " 'amicable',\n",
       " 'amicably',\n",
       " 'amity',\n",
       " 'amity',\n",
       " 'amnesty',\n",
       " 'amour',\n",
       " 'ample',\n",
       " 'amply',\n",
       " 'amusement',\n",
       " 'amusement',\n",
       " 'amusing',\n",
       " 'angel',\n",
       " 'angelic',\n",
       " 'animated',\n",
       " 'apostle',\n",
       " 'apostle',\n",
       " 'apotheosis',\n",
       " 'apotheosis',\n",
       " 'appeal',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appreciable',\n",
       " 'appreciation',\n",
       " 'appreciation',\n",
       " 'appreciative',\n",
       " 'appropriate',\n",
       " 'approval',\n",
       " 'apt',\n",
       " 'aptly',\n",
       " 'aptitude',\n",
       " 'ardent',\n",
       " 'ardently',\n",
       " 'ardor',\n",
       " 'aristocratic',\n",
       " 'arresting',\n",
       " 'articulate',\n",
       " 'ascendant',\n",
       " 'ascendant',\n",
       " 'ascertainable',\n",
       " 'ascertainable',\n",
       " 'aspiration',\n",
       " 'aspirations',\n",
       " 'aspirations',\n",
       " 'assertions',\n",
       " 'assertions',\n",
       " 'assertive',\n",
       " 'asset',\n",
       " 'assiduous',\n",
       " 'assiduously',\n",
       " 'assurance',\n",
       " 'assurance',\n",
       " 'assurances',\n",
       " 'assurances',\n",
       " 'assuredly',\n",
       " 'astonished',\n",
       " 'astonishing',\n",
       " 'astonishingly',\n",
       " 'astonishment',\n",
       " 'astounded',\n",
       " 'astounding',\n",
       " 'astounding',\n",
       " 'astoundingly',\n",
       " 'astute',\n",
       " 'astutely',\n",
       " 'asylum',\n",
       " 'asylum',\n",
       " 'attainable',\n",
       " 'attentive',\n",
       " 'attraction',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'attractive',\n",
       " 'attune',\n",
       " 'auspicious',\n",
       " 'authentic',\n",
       " 'authoritative',\n",
       " 'award',\n",
       " 'autonomous',\n",
       " 'avid',\n",
       " 'avidly',\n",
       " 'awe',\n",
       " 'awed',\n",
       " 'awesome',\n",
       " 'awesomely',\n",
       " 'awesomeness',\n",
       " 'awestruck',\n",
       " 'backbone',\n",
       " 'balanced',\n",
       " 'bargain',\n",
       " 'bargain',\n",
       " 'basic',\n",
       " 'beacon',\n",
       " 'beauteous',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'befitting',\n",
       " 'believable',\n",
       " 'beloved',\n",
       " 'benefactor',\n",
       " 'beneficial',\n",
       " 'beneficent',\n",
       " 'beneficiary',\n",
       " 'beneficiary',\n",
       " 'benefit',\n",
       " 'benefit',\n",
       " 'benefits',\n",
       " 'benefits',\n",
       " 'benevolence',\n",
       " 'benevolent',\n",
       " 'benign',\n",
       " 'best-known',\n",
       " 'best-performing',\n",
       " 'best-selling',\n",
       " 'better',\n",
       " 'better-known',\n",
       " 'better-than-expected',\n",
       " 'blameless',\n",
       " 'blessing',\n",
       " 'blessing',\n",
       " 'bliss',\n",
       " 'blissful',\n",
       " 'blissfully',\n",
       " 'blithe',\n",
       " 'bold',\n",
       " 'boldly',\n",
       " 'boldness',\n",
       " 'bonny',\n",
       " 'bonus',\n",
       " 'boom',\n",
       " 'booming',\n",
       " 'boost',\n",
       " 'boundless',\n",
       " 'bountiful',\n",
       " 'brains',\n",
       " 'brains',\n",
       " 'brainy',\n",
       " 'brave',\n",
       " 'bravery',\n",
       " 'bravery',\n",
       " 'breakthrough',\n",
       " 'breakthrough',\n",
       " 'breakthroughs',\n",
       " 'breakthroughs',\n",
       " 'breathlessness',\n",
       " 'breathlessness',\n",
       " 'breathtaking',\n",
       " 'breathtakingly',\n",
       " 'bright',\n",
       " 'brightness',\n",
       " 'brilliance',\n",
       " 'brilliant',\n",
       " 'brilliantly',\n",
       " 'brisk',\n",
       " 'broad',\n",
       " 'brotherly',\n",
       " 'bull',\n",
       " 'bull',\n",
       " 'bullish',\n",
       " 'bullish',\n",
       " 'buoyant',\n",
       " 'calm',\n",
       " 'calmness',\n",
       " 'candid',\n",
       " 'candor',\n",
       " 'capable',\n",
       " 'capability',\n",
       " 'capably',\n",
       " 'captivating',\n",
       " 'captivation',\n",
       " 'carefree',\n",
       " 'careful',\n",
       " 'catalyst',\n",
       " 'catalyst',\n",
       " 'catchy',\n",
       " 'celebrated',\n",
       " 'celebration',\n",
       " 'celebrity',\n",
       " 'champion',\n",
       " 'champ',\n",
       " 'champion',\n",
       " 'charismatic',\n",
       " 'charitable',\n",
       " 'charitable',\n",
       " 'charity',\n",
       " 'charm',\n",
       " 'charm',\n",
       " 'charming',\n",
       " 'charming',\n",
       " 'charmingly',\n",
       " 'chaste',\n",
       " 'cheer',\n",
       " 'cheery',\n",
       " 'cheerful',\n",
       " 'cherished',\n",
       " 'cherub',\n",
       " 'chic',\n",
       " 'chivalry',\n",
       " 'chivalrous',\n",
       " 'chum',\n",
       " 'civility',\n",
       " 'civilization',\n",
       " 'civilize',\n",
       " 'civil',\n",
       " 'clarity',\n",
       " 'classic',\n",
       " 'clean',\n",
       " 'cleanliness',\n",
       " 'cleanse',\n",
       " 'clear-cut',\n",
       " 'clearer',\n",
       " 'clearer',\n",
       " 'clearly',\n",
       " 'clever',\n",
       " 'closeness',\n",
       " 'closeness',\n",
       " 'clout',\n",
       " 'clout',\n",
       " 'co-operation',\n",
       " 'co-operation',\n",
       " 'cogent',\n",
       " 'cohesive',\n",
       " 'coherence',\n",
       " 'coherence',\n",
       " 'coherent',\n",
       " 'cohesion',\n",
       " 'cohesive',\n",
       " 'colorful',\n",
       " 'colossal',\n",
       " 'comeback',\n",
       " 'comeback',\n",
       " 'comely',\n",
       " 'comfortable',\n",
       " 'comfortable',\n",
       " 'comfortably',\n",
       " 'comforting',\n",
       " 'commendable',\n",
       " 'commendably',\n",
       " 'commensurate',\n",
       " 'commonsense',\n",
       " 'commonsensible',\n",
       " 'commonsensibly',\n",
       " 'commonsensical',\n",
       " 'commodious',\n",
       " 'commitment',\n",
       " 'commitment',\n",
       " 'compact',\n",
       " 'compassion',\n",
       " 'compassionate',\n",
       " 'compatible',\n",
       " 'compatible',\n",
       " 'compelling',\n",
       " 'compelling',\n",
       " 'competent',\n",
       " 'competence',\n",
       " 'competency',\n",
       " 'competitive',\n",
       " 'competitive',\n",
       " 'competitiveness',\n",
       " 'complement',\n",
       " 'compliant',\n",
       " 'compliant',\n",
       " 'complimentary',\n",
       " 'comprehensive',\n",
       " 'compromise',\n",
       " 'compromise',\n",
       " 'compromises',\n",
       " 'compromises',\n",
       " 'comrades',\n",
       " 'comrades',\n",
       " 'conceivable',\n",
       " 'conceivable',\n",
       " 'conciliatory',\n",
       " 'conclusive',\n",
       " 'concrete',\n",
       " 'conducive',\n",
       " 'conducive',\n",
       " 'confidence',\n",
       " 'confidence',\n",
       " 'confident',\n",
       " 'congenial',\n",
       " 'congratulations',\n",
       " 'congratulations',\n",
       " 'conscience',\n",
       " 'conscientious',\n",
       " 'consensus',\n",
       " 'considerate',\n",
       " 'consistent',\n",
       " 'constancy',\n",
       " 'constructive',\n",
       " 'constructive',\n",
       " 'constructive',\n",
       " 'consummate',\n",
       " 'content',\n",
       " 'contentment',\n",
       " 'continuity',\n",
       " 'contribution',\n",
       " 'contribution',\n",
       " 'convenient',\n",
       " 'convenient',\n",
       " 'conviction',\n",
       " 'conviction',\n",
       " 'convincing',\n",
       " 'convincing',\n",
       " 'convincingly',\n",
       " 'cooperation',\n",
       " 'cooperation',\n",
       " 'cooperative',\n",
       " 'cooperatively',\n",
       " 'cordial',\n",
       " 'cornerstone',\n",
       " 'cornerstone',\n",
       " 'correct',\n",
       " 'cost-effective',\n",
       " 'cost-saving',\n",
       " 'courage',\n",
       " 'courage',\n",
       " 'courageous',\n",
       " 'courageously',\n",
       " 'courageousness',\n",
       " 'courteous',\n",
       " 'courtesy',\n",
       " 'courtly',\n",
       " 'covenant',\n",
       " 'cozy',\n",
       " 'craving',\n",
       " 'creative',\n",
       " 'credence',\n",
       " 'credence',\n",
       " 'credible',\n",
       " 'crisp',\n",
       " 'crusade',\n",
       " 'crusade',\n",
       " 'crusader',\n",
       " 'cure-all',\n",
       " 'cure-all',\n",
       " 'cute',\n",
       " 'dance',\n",
       " 'daring',\n",
       " 'daringly',\n",
       " 'dashing',\n",
       " 'dauntless',\n",
       " 'dazzled',\n",
       " 'dazzling',\n",
       " 'deal',\n",
       " 'dear',\n",
       " 'decent',\n",
       " 'decency',\n",
       " 'decisive',\n",
       " 'decisiveness',\n",
       " 'decisiveness',\n",
       " 'dedicated',\n",
       " 'defender',\n",
       " 'defender',\n",
       " 'deference',\n",
       " 'defense',\n",
       " 'definite',\n",
       " 'definitive',\n",
       " 'definitive',\n",
       " 'definitively',\n",
       " 'deflationary',\n",
       " 'deft',\n",
       " 'delectable',\n",
       " 'delicacy',\n",
       " 'delicate',\n",
       " 'delicious',\n",
       " 'delight',\n",
       " 'delighted',\n",
       " 'delightful',\n",
       " 'delightful',\n",
       " 'delightfully',\n",
       " 'delightfulness',\n",
       " 'democratic',\n",
       " 'dependable',\n",
       " 'deserved',\n",
       " 'deservedly',\n",
       " 'deserving',\n",
       " 'desirable',\n",
       " 'desire',\n",
       " 'desire',\n",
       " 'desirous',\n",
       " 'destined',\n",
       " 'destinies',\n",
       " 'destinies',\n",
       " 'destiny',\n",
       " 'determination',\n",
       " 'determination',\n",
       " 'devoted',\n",
       " 'devotee',\n",
       " 'devotion',\n",
       " 'devout',\n",
       " 'dexterity',\n",
       " 'dexterous',\n",
       " 'dexterously',\n",
       " 'dextrous',\n",
       " 'dignified',\n",
       " 'dignity',\n",
       " 'diligence',\n",
       " 'diligent',\n",
       " 'diligently',\n",
       " 'diplomatic',\n",
       " 'diplomatic',\n",
       " 'discerning',\n",
       " 'discreet',\n",
       " 'discreet',\n",
       " 'discretion',\n",
       " 'discriminating',\n",
       " 'discriminatingly',\n",
       " 'distinct',\n",
       " 'distinction',\n",
       " 'distinctive',\n",
       " 'distinctive',\n",
       " 'distinctive',\n",
       " 'distinguished',\n",
       " 'diversified',\n",
       " 'divine',\n",
       " 'divinely',\n",
       " 'dodge',\n",
       " 'dodge',\n",
       " 'dotingly',\n",
       " 'doubtless',\n",
       " 'dream',\n",
       " 'dream',\n",
       " 'dreamland',\n",
       " 'dreams',\n",
       " 'dreams',\n",
       " 'dreamy',\n",
       " 'drive',\n",
       " 'driven',\n",
       " 'durable',\n",
       " 'durability',\n",
       " 'dynamic',\n",
       " 'eager',\n",
       " 'eagerly',\n",
       " 'eagerness',\n",
       " 'earnest',\n",
       " 'earnestly',\n",
       " 'earnestness',\n",
       " 'ease',\n",
       " 'easy',\n",
       " 'easygoing',\n",
       " 'ebullience',\n",
       " 'ebullient',\n",
       " 'ebulliently',\n",
       " 'eclectic',\n",
       " 'economical',\n",
       " 'ecstasies',\n",
       " 'ecstasy',\n",
       " 'ecstatic',\n",
       " 'ecstatically',\n",
       " 'educable',\n",
       " 'educated',\n",
       " 'educational',\n",
       " 'effective',\n",
       " 'effectiveness',\n",
       " 'effectual',\n",
       " 'efficacious',\n",
       " 'efficiency',\n",
       " 'efficient',\n",
       " 'effortless',\n",
       " 'effortlessly',\n",
       " 'effusion',\n",
       " 'effusive',\n",
       " 'effusively',\n",
       " 'effusiveness',\n",
       " 'egalitarian',\n",
       " 'elan',\n",
       " 'elated',\n",
       " 'elatedly',\n",
       " 'elation',\n",
       " 'electrification',\n",
       " 'electrification',\n",
       " 'elegance',\n",
       " 'elegant',\n",
       " 'elegantly',\n",
       " 'elevated',\n",
       " 'eligible',\n",
       " 'elite',\n",
       " 'eloquence',\n",
       " 'eloquent',\n",
       " 'eloquently',\n",
       " 'eminence',\n",
       " 'eminent',\n",
       " 'empowerment',\n",
       " 'enchanted',\n",
       " 'enchanting',\n",
       " 'enchantingly',\n",
       " 'encouragement',\n",
       " 'encouragement',\n",
       " 'encouraging',\n",
       " 'encouraging',\n",
       " 'encouragingly',\n",
       " 'endearing',\n",
       " 'endorsement',\n",
       " 'endorsement',\n",
       " 'endorser',\n",
       " 'endurable',\n",
       " 'enduring',\n",
       " 'energetic',\n",
       " 'energetic',\n",
       " 'engaging',\n",
       " 'engrossing',\n",
       " 'enhanced',\n",
       " 'enhancement',\n",
       " 'enjoyable',\n",
       " 'enjoyably',\n",
       " 'enjoyment',\n",
       " 'enlightenment',\n",
       " 'enrapt',\n",
       " 'enrichment',\n",
       " 'enterprising',\n",
       " 'entertaining',\n",
       " 'enthusiasm',\n",
       " 'enthusiast',\n",
       " 'enthusiastic',\n",
       " 'enthusiastically',\n",
       " 'enticing',\n",
       " 'enticingly',\n",
       " 'entrancing',\n",
       " 'entreatingly',\n",
       " 'enviable',\n",
       " 'enviably',\n",
       " 'envisions',\n",
       " 'envisions',\n",
       " 'epic',\n",
       " 'epitome',\n",
       " 'equality',\n",
       " 'equality',\n",
       " 'equitable',\n",
       " 'erudite',\n",
       " 'essential',\n",
       " 'especially',\n",
       " 'esteem',\n",
       " 'established',\n",
       " 'eternity',\n",
       " 'eternity',\n",
       " 'ethical',\n",
       " 'euphoria',\n",
       " 'euphoric',\n",
       " 'euphorically',\n",
       " 'even',\n",
       " 'evenly',\n",
       " 'eventful',\n",
       " 'everlasting',\n",
       " 'evocative',\n",
       " 'exalt',\n",
       " 'exaltation',\n",
       " 'exalted',\n",
       " 'exaltedly',\n",
       " 'exalting',\n",
       " 'exaltingly',\n",
       " 'exceeding',\n",
       " 'exceedingly',\n",
       " 'excellence',\n",
       " 'excellency',\n",
       " 'excellent',\n",
       " 'excellently',\n",
       " 'exceptional',\n",
       " 'exceptionally',\n",
       " 'excited',\n",
       " 'excitedly',\n",
       " 'excitedness',\n",
       " 'excitement',\n",
       " 'exciting',\n",
       " 'excitingly',\n",
       " 'exclusive',\n",
       " 'excusable',\n",
       " 'excusable',\n",
       " 'exemplar',\n",
       " 'exemplary',\n",
       " 'exhaustive',\n",
       " 'exhaustively',\n",
       " 'exhilarating',\n",
       " 'exhilaratingly',\n",
       " 'exhilaration',\n",
       " 'expansive',\n",
       " 'experienced',\n",
       " 'expert',\n",
       " 'expertly',\n",
       " 'explicit',\n",
       " 'explicitly',\n",
       " 'expressive',\n",
       " 'exquisite',\n",
       " 'exquisitely',\n",
       " 'extraordinarily',\n",
       " 'extraordinary',\n",
       " 'exuberance',\n",
       " 'exuberant',\n",
       " 'exuberantly',\n",
       " 'exultation',\n",
       " 'exultingly',\n",
       " 'fabulous',\n",
       " 'fabulously',\n",
       " 'fair',\n",
       " 'fair',\n",
       " 'fairly',\n",
       " 'fairness',\n",
       " 'fairness',\n",
       " 'faith',\n",
       " 'faith',\n",
       " 'faithful',\n",
       " 'faithful',\n",
       " 'faithfully',\n",
       " 'faithfulness',\n",
       " 'famed',\n",
       " 'fame',\n",
       " 'famed',\n",
       " 'famous',\n",
       " 'famously',\n",
       " 'fancy',\n",
       " 'fanfare',\n",
       " 'fanfare',\n",
       " 'fantastic',\n",
       " 'fantastically',\n",
       " 'fantasy',\n",
       " 'fantasy',\n",
       " 'farsighted',\n",
       " 'fascinating',\n",
       " 'fascinatingly',\n",
       " 'fascination',\n",
       " 'fashionable',\n",
       " 'fashionably',\n",
       " 'fast-growing',\n",
       " 'fast-paced',\n",
       " 'fastest-growing',\n",
       " 'favor',\n",
       " 'favor',\n",
       " 'favorable',\n",
       " 'favored',\n",
       " 'favorite',\n",
       " 'favour',\n",
       " 'fearless',\n",
       " 'fearlessly',\n",
       " 'feasible',\n",
       " 'feasibly',\n",
       " 'feat',\n",
       " 'featly',\n",
       " 'feisty',\n",
       " 'feisty',\n",
       " 'felicitous',\n",
       " 'felicity',\n",
       " 'fertile',\n",
       " 'fertile',\n",
       " 'fervent',\n",
       " 'fervently',\n",
       " 'fervid',\n",
       " 'fervidly',\n",
       " 'fervor',\n",
       " 'festive',\n",
       " 'fidelity',\n",
       " 'fiery',\n",
       " 'fine',\n",
       " 'finely',\n",
       " 'first-class',\n",
       " 'first-rate',\n",
       " 'fit',\n",
       " 'fitting',\n",
       " 'flair',\n",
       " 'flame',\n",
       " 'flame',\n",
       " 'flattering',\n",
       " 'flatteringly',\n",
       " 'flawless',\n",
       " 'flawlessly',\n",
       " 'flexible',\n",
       " 'flourish',\n",
       " 'flourishing',\n",
       " 'fluent',\n",
       " 'fond',\n",
       " 'fondly',\n",
       " 'fondness',\n",
       " 'foolproof',\n",
       " 'foremost',\n",
       " 'foresight',\n",
       " 'forgave',\n",
       " 'forgiven',\n",
       " 'forgiveness',\n",
       " 'forgiving',\n",
       " 'forgivingly',\n",
       " 'fortitude',\n",
       " 'fortuitous',\n",
       " 'fortuitously',\n",
       " 'fortunate',\n",
       " 'fortune',\n",
       " 'fortune',\n",
       " 'fragrant',\n",
       " 'frank',\n",
       " 'free',\n",
       " 'freedom',\n",
       " 'freedom',\n",
       " 'freedoms',\n",
       " 'freedoms',\n",
       " 'fresh',\n",
       " 'friend',\n",
       " 'friend',\n",
       " 'friendliness',\n",
       " 'friendliness',\n",
       " 'friendly',\n",
       " 'friends',\n",
       " 'friends',\n",
       " 'friendship',\n",
       " 'friendship',\n",
       " 'fruitful',\n",
       " 'fulfillment',\n",
       " 'fulfillment',\n",
       " 'full-fledged',\n",
       " 'fun',\n",
       " 'functional',\n",
       " 'funny',\n",
       " 'gaiety',\n",
       " 'gaily',\n",
       " 'gain',\n",
       " 'gainful',\n",
       " 'gainfully',\n",
       " 'gallant',\n",
       " 'gallantly',\n",
       " 'galore',\n",
       " 'gem',\n",
       " 'gem',\n",
       " 'gems',\n",
       " 'gems',\n",
       " 'generosity',\n",
       " 'generous',\n",
       " 'generously',\n",
       " 'genial',\n",
       " 'genius',\n",
       " 'gentle',\n",
       " 'genuine',\n",
       " 'germane',\n",
       " 'giddy',\n",
       " 'gifted',\n",
       " 'glad',\n",
       " 'gladly',\n",
       " 'gladness',\n",
       " 'glamorous',\n",
       " 'glee',\n",
       " 'gleeful',\n",
       " 'gleefully',\n",
       " 'glimmer',\n",
       " 'glimmer',\n",
       " 'glimmering',\n",
       " 'glisten',\n",
       " 'glistening',\n",
       " 'glitter',\n",
       " 'glorious',\n",
       " 'gloriously',\n",
       " 'glory',\n",
       " 'glossy',\n",
       " 'glowingly',\n",
       " 'go-ahead',\n",
       " 'go-ahead',\n",
       " 'god-given',\n",
       " 'godlike',\n",
       " 'gold',\n",
       " 'golden',\n",
       " 'good',\n",
       " 'goodly',\n",
       " 'goodness',\n",
       " 'goodwill',\n",
       " 'goodwill',\n",
       " 'gorgeous',\n",
       " 'gorgeously',\n",
       " 'grace',\n",
       " 'graceful',\n",
       " 'gracefully',\n",
       " 'gracious',\n",
       " 'graciously',\n",
       " 'graciousness',\n",
       " 'grail',\n",
       " 'grail',\n",
       " 'grand',\n",
       " 'grandeur',\n",
       " 'grateful',\n",
       " 'grateful',\n",
       " 'gratefully',\n",
       " 'gratification',\n",
       " 'gratifying',\n",
       " 'gratifyingly',\n",
       " 'gratitude',\n",
       " 'gratitude',\n",
       " 'great',\n",
       " 'greatest',\n",
       " 'greatness',\n",
       " 'grit',\n",
       " 'grit',\n",
       " 'groundbreaking',\n",
       " 'groundbreaking',\n",
       " 'guarantee',\n",
       " 'guardian',\n",
       " 'guidance',\n",
       " 'guidance',\n",
       " 'guiltless',\n",
       " 'gumption',\n",
       " 'gusto',\n",
       " 'gutsy',\n",
       " 'halcyon',\n",
       " 'hale',\n",
       " 'hallowed',\n",
       " 'handily',\n",
       " 'handsome',\n",
       " 'handy',\n",
       " 'happily',\n",
       " 'happiness',\n",
       " 'happy',\n",
       " 'hard-working',\n",
       " 'hardier',\n",
       " 'hardier',\n",
       " 'hardy',\n",
       " 'harmless',\n",
       " 'harmonious',\n",
       " 'harmony',\n",
       " 'harmony',\n",
       " 'haven',\n",
       " 'headway',\n",
       " 'heady',\n",
       " 'healthful',\n",
       " 'healthy',\n",
       " 'healthy',\n",
       " 'heart',\n",
       " 'heartening',\n",
       " 'heartfelt',\n",
       " 'heartily',\n",
       " 'heartwarming',\n",
       " 'heaven',\n",
       " 'heavenly',\n",
       " 'help',\n",
       " 'help',\n",
       " 'helpful',\n",
       " 'hero',\n",
       " 'heroic',\n",
       " 'heroically',\n",
       " 'heroine',\n",
       " 'heros',\n",
       " 'high-quality',\n",
       " 'highlight',\n",
       " 'hilarious',\n",
       " 'hilariously',\n",
       " 'hilariousness',\n",
       " 'hilarity',\n",
       " 'historic',\n",
       " 'holy',\n",
       " 'homage',\n",
       " 'honest',\n",
       " 'honest',\n",
       " 'honestly',\n",
       " 'honesty',\n",
       " 'honesty',\n",
       " 'honeymoon',\n",
       " 'honor',\n",
       " 'honor',\n",
       " 'honorable',\n",
       " 'hope',\n",
       " 'hope',\n",
       " 'hopeful',\n",
       " 'hopefully',\n",
       " 'hopefulness',\n",
       " 'hopes',\n",
       " 'hopes',\n",
       " 'hospitable',\n",
       " 'hot',\n",
       " 'hug',\n",
       " 'hug',\n",
       " 'humane',\n",
       " 'humane',\n",
       " 'humanists',\n",
       " 'humanists',\n",
       " 'humanity',\n",
       " 'humankind',\n",
       " 'humility',\n",
       " 'humorous',\n",
       " 'humorously',\n",
       " 'humour',\n",
       " 'humour',\n",
       " 'humourous',\n",
       " 'ideal',\n",
       " 'ideal',\n",
       " 'idealism',\n",
       " 'idealist',\n",
       " 'idol',\n",
       " 'idol',\n",
       " 'idolized',\n",
       " 'illuminati',\n",
       " 'illuminati',\n",
       " 'illuminating',\n",
       " 'illustrious',\n",
       " 'imaginative',\n",
       " 'immaculate',\n",
       " 'immaculately',\n",
       " 'impartial',\n",
       " 'impartiality',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remember the split function? We'll split on the newline character (\\n) to create a list\n",
    "positive_words=pos_sent.split('\\n')\n",
    "negative_words=neg_sent.split('\\n')\n",
    "\n",
    "#view the first elements in the lists\n",
    "print(positive_words[:10])\n",
    "print(negative_words[:10])\n",
    "positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2231\n",
      "3906\n"
     ]
    }
   ],
   "source": [
    "#count number of words in each list\n",
    "print(len(positive_words))\n",
    "print(len(negative_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You know what to do now.\n",
    "\n",
    "### Challenge\n",
    "1. Create a column with the number of positive words, and another with the proportion of positive words\n",
    "2. Create a column with the number of negative words, and another with the proportion of negative words\n",
    "3. Print the average proportion of negative and positive words by genre\n",
    "4. Compare this to the average score by genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>critic</th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "      <th>body_tokens</th>\n",
       "      <th>token_count</th>\n",
       "      <th>pos_num</th>\n",
       "      <th>neg_num</th>\n",
       "      <th>pos_prop</th>\n",
       "      <th>neg_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don't Panic</td>\n",
       "      <td>All Time Low</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>Kerrang!</td>\n",
       "      <td>74.0</td>\n",
       "      <td>While For Baltimore proves they can still writ...</td>\n",
       "      <td>[while, for, baltimore, proves, they, can, sti...</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fear and Saturday Night</td>\n",
       "      <td>Ryan Bingham</td>\n",
       "      <td>Country</td>\n",
       "      <td>Uncut</td>\n",
       "      <td>70.0</td>\n",
       "      <td>There's nothing fake about the purgatorial nar...</td>\n",
       "      <td>[there, 's, nothing, fake, about, the, purgato...</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Way I'm Livin'</td>\n",
       "      <td>Lee Ann Womack</td>\n",
       "      <td>Country</td>\n",
       "      <td>Q Magazine</td>\n",
       "      <td>84.0</td>\n",
       "      <td>All life's disastrous lows are here on a caree...</td>\n",
       "      <td>[all, life, 's, disastrous, lows, are, here, o...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doris</td>\n",
       "      <td>Earl Sweatshirt</td>\n",
       "      <td>Rap</td>\n",
       "      <td>Pitchfork</td>\n",
       "      <td>82.0</td>\n",
       "      <td>With Doris, Odd Future’s Odysseus is finally b...</td>\n",
       "      <td>[with, doris, odd, future, ’, s, odysseus, is,...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Giraffe</td>\n",
       "      <td>Echoboy</td>\n",
       "      <td>Rock</td>\n",
       "      <td>AllMusic</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Though Giraffe is definitely Echoboy's most im...</td>\n",
       "      <td>[though, giraffe, is, definitely, echoboy, 's,...</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.078431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Outer South</td>\n",
       "      <td>Conor Oberst And The Mystic Valley Band</td>\n",
       "      <td>Indie</td>\n",
       "      <td>Slant Magazine</td>\n",
       "      <td>67.0</td>\n",
       "      <td>The result is an album that's unfortunately ba...</td>\n",
       "      <td>[the, result, is, an, album, that, 's, unfortu...</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>On An Island</td>\n",
       "      <td>David Gilmour</td>\n",
       "      <td>Rock</td>\n",
       "      <td>E! Online</td>\n",
       "      <td>67.0</td>\n",
       "      <td>In the end, Island makes Dave sound like he's ...</td>\n",
       "      <td>[in, the, end, island, makes, dave, sound, lik...</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Movement</td>\n",
       "      <td>Gossip</td>\n",
       "      <td>Indie</td>\n",
       "      <td>Uncut</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Beth Ditto's remarkable gospel holler and ferv...</td>\n",
       "      <td>[beth, ditto, 's, remarkable, gospel, holler, ...</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Locked Down</td>\n",
       "      <td>Dr. John</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>PopMatters</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Dr. John is Dr. John. He's a star, and is on f...</td>\n",
       "      <td>[dr., john, is, dr., john, he, 's, a, star, an...</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>And Their Refinement Of The Decline</td>\n",
       "      <td>Stars Of The Lid</td>\n",
       "      <td>Rock</td>\n",
       "      <td>PopMatters</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Their work, especially that displayed on Refin...</td>\n",
       "      <td>[their, work, especially, that, displayed, on,...</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5001 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    album  \\\n",
       "0                             Don't Panic   \n",
       "1                 Fear and Saturday Night   \n",
       "2                      The Way I'm Livin'   \n",
       "3                                   Doris   \n",
       "4                                 Giraffe   \n",
       "...                                   ...   \n",
       "4996                          Outer South   \n",
       "4997                         On An Island   \n",
       "4998                             Movement   \n",
       "4999                          Locked Down   \n",
       "5000  And Their Refinement Of The Decline   \n",
       "\n",
       "                                       artist     genre          critic  \\\n",
       "0                                All Time Low  Pop/Rock        Kerrang!   \n",
       "1                                Ryan Bingham   Country           Uncut   \n",
       "2                              Lee Ann Womack   Country      Q Magazine   \n",
       "3                             Earl Sweatshirt       Rap       Pitchfork   \n",
       "4                                     Echoboy      Rock        AllMusic   \n",
       "...                                       ...       ...             ...   \n",
       "4996  Conor Oberst And The Mystic Valley Band     Indie  Slant Magazine   \n",
       "4997                            David Gilmour      Rock       E! Online   \n",
       "4998                                   Gossip     Indie           Uncut   \n",
       "4999                                 Dr. John  Pop/Rock      PopMatters   \n",
       "5000                         Stars Of The Lid      Rock      PopMatters   \n",
       "\n",
       "      score                                               body  \\\n",
       "0      74.0  While For Baltimore proves they can still writ...   \n",
       "1      70.0  There's nothing fake about the purgatorial nar...   \n",
       "2      84.0  All life's disastrous lows are here on a caree...   \n",
       "3      82.0  With Doris, Odd Future’s Odysseus is finally b...   \n",
       "4      71.0  Though Giraffe is definitely Echoboy's most im...   \n",
       "...     ...                                                ...   \n",
       "4996   67.0  The result is an album that's unfortunately ba...   \n",
       "4997   67.0  In the end, Island makes Dave sound like he's ...   \n",
       "4998   81.0  Beth Ditto's remarkable gospel holler and ferv...   \n",
       "4999   86.0  Dr. John is Dr. John. He's a star, and is on f...   \n",
       "5000   87.0  Their work, especially that displayed on Refin...   \n",
       "\n",
       "                                            body_tokens  token_count  pos_num  \\\n",
       "0     [while, for, baltimore, proves, they, can, sti...           38        1   \n",
       "1     [there, 's, nothing, fake, about, the, purgato...           28        0   \n",
       "2     [all, life, 's, disastrous, lows, are, here, o...           13        0   \n",
       "3     [with, doris, odd, future, ’, s, odysseus, is,...           18        0   \n",
       "4     [though, giraffe, is, definitely, echoboy, 's,...           51        2   \n",
       "...                                                 ...          ...      ...   \n",
       "4996  [the, result, is, an, album, that, 's, unfortu...           27        0   \n",
       "4997  [in, the, end, island, makes, dave, sound, lik...           17        3   \n",
       "4998  [beth, ditto, 's, remarkable, gospel, holler, ...           25        2   \n",
       "4999  [dr., john, is, dr., john, he, 's, a, star, an...           18        1   \n",
       "5000  [their, work, especially, that, displayed, on,...           28        5   \n",
       "\n",
       "      neg_num  pos_prop  neg_prop  \n",
       "0           0  0.026316  0.000000  \n",
       "1           3  0.000000  0.107143  \n",
       "2           1  0.000000  0.076923  \n",
       "3           1  0.000000  0.055556  \n",
       "4           4  0.039216  0.078431  \n",
       "...       ...       ...       ...  \n",
       "4996        3  0.000000  0.111111  \n",
       "4997        0  0.176471  0.000000  \n",
       "4998        0  0.080000  0.000000  \n",
       "4999        0  0.055556  0.000000  \n",
       "5000        0  0.178571  0.000000  \n",
       "\n",
       "[5001 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pos_num'] = df['body_tokens'].apply(lambda x: len([word for word in x if word in positive_words]))\n",
    "df['neg_num'] = df['body_tokens'].apply(lambda x: len([word for word in x if word in negative_words]))\n",
    "\n",
    "df['pos_prop'] = df['pos_num']/df['token_count']\n",
    "df['neg_prop'] = df['neg_num']/df['token_count']\n",
    "df.drop('release_date', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Folk                      0.096497\n",
       "Jazz                      0.087290\n",
       "Indie                     0.085293\n",
       "Alternative/Indie Rock    0.080572\n",
       "Rock                      0.080200\n",
       "Electronic                0.078628\n",
       "Dance                     0.078059\n",
       "Pop/Rock                  0.077627\n",
       "R&B;                      0.074498\n",
       "Country                   0.072140\n",
       "Rap                       0.070954\n",
       "Pop                       0.069679\n",
       "Name: pos_prop, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df.groupby('genre')\n",
    "grouped['pos_prop'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Jazz                      77.631579\n",
       "Folk                      75.900000\n",
       "Indie                     74.400897\n",
       "Country                   74.071429\n",
       "Alternative/Indie Rock    73.928571\n",
       "Electronic                73.140351\n",
       "Pop/Rock                  73.033782\n",
       "R&B;                      72.366071\n",
       "Rap                       72.173554\n",
       "Rock                      70.754292\n",
       "Dance                     70.146341\n",
       "Pop                       64.608054\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped['score'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the dictionary method! You can do this with any dictionary you want, standard or you can create your own.\n",
    "\n",
    "## 0.3. Sentiment analysis using scikit-learn\n",
    "\n",
    "We can also do this using the document term matrix. We'll do this in pandas, to make it conceptually clear. As you get more comfortable with programming you may want to eventually shift over to working with sparse matrix format, which is more efficient to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aahs</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abc</th>\n",
       "      <th>...</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zooey</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zu</th>\n",
       "      <th>zydeco</th>\n",
       "      <th>álbum</th>\n",
       "      <th>être</th>\n",
       "      <th>über</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5001 rows × 16139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aaaa  aahs  aaliyah  aaron  ab  abandon  abandoned  abandoning  abc  \\\n",
       "0      0     0     0        0      0   0        0          0           0    0   \n",
       "1      0     0     0        0      0   0        0          0           0    0   \n",
       "2      0     0     0        0      0   0        0          0           0    0   \n",
       "3      0     0     0        0      0   0        0          0           0    0   \n",
       "4      0     0     0        0      0   0        0          0           0    0   \n",
       "...   ..   ...   ...      ...    ...  ..      ...        ...         ...  ...   \n",
       "4996   0     0     0        0      0   0        0          0           0    0   \n",
       "4997   0     0     0        0      0   0        0          0           0    0   \n",
       "4998   0     0     0        0      0   0        0          0           0    0   \n",
       "4999   0     0     0        0      0   0        0          0           0    0   \n",
       "5000   0     0     0        0      0   0        0          0           0    0   \n",
       "\n",
       "      ...  zone  zones  zoo  zooey  zoomer  zu  zydeco  álbum  être  über  \n",
       "0     ...     0      0    0      0       0   0       0      0     0     0  \n",
       "1     ...     0      0    0      0       0   0       0      0     0     0  \n",
       "2     ...     0      0    0      0       0   0       0      0     0     0  \n",
       "3     ...     0      0    0      0       0   0       0      0     0     0  \n",
       "4     ...     0      0    0      0       0   0       0      0     0     0  \n",
       "...   ...   ...    ...  ...    ...     ...  ..     ...    ...   ...   ...  \n",
       "4996  ...     0      0    0      0       0   0       0      0     0     0  \n",
       "4997  ...     0      0    0      0       0   0       0      0     0     0  \n",
       "4998  ...     0      0    0      0       0   0       0      0     0     0  \n",
       "4999  ...     0      0    0      0       0   0       0      0     0     0  \n",
       "5000  ...     0      0    0      0       0   0       0      0     0     0  \n",
       "\n",
       "[5001 rows x 16139 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the function CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "countvec = CountVectorizer()\n",
    "\n",
    "#create our document term matrix as a pandas dataframe\n",
    "dtm_df = pandas.DataFrame(countvec.fit_transform(df.body).toarray(), columns=countvec.get_feature_names(), index = df.index)\n",
    "dtm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can keep only those *columns* that occur in our positive words list. To do this, we'll first save a list of the columns names as a variable, and then only keep the elements of the list that occur in our positive words list. We'll then create a new dataframe keeping only those select columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaaa',\n",
       " 'aahs',\n",
       " 'aaliyah',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abc',\n",
       " 'abdullah',\n",
       " 'abe',\n",
       " 'aberrant',\n",
       " 'abhorrent',\n",
       " 'abides',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'ablaze',\n",
       " 'able',\n",
       " 'ably',\n",
       " 'abortively',\n",
       " 'abound',\n",
       " 'abounds',\n",
       " 'about',\n",
       " 'aboutsonic',\n",
       " 'above',\n",
       " 'abovei',\n",
       " 'abrasive',\n",
       " 'abrupt',\n",
       " 'absence',\n",
       " 'absenceit',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolution',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'absorbs',\n",
       " 'abstract',\n",
       " 'abstruse',\n",
       " 'absurd',\n",
       " 'absurdities',\n",
       " 'absurdity',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abuse',\n",
       " 'abusers',\n",
       " 'abusing',\n",
       " 'abysmal',\n",
       " 'abyss',\n",
       " 'ac',\n",
       " 'accelerate',\n",
       " 'accelerating',\n",
       " 'accent',\n",
       " 'accented',\n",
       " 'accents',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepting',\n",
       " 'access',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'acclimatise',\n",
       " 'accompanied',\n",
       " 'accompaniment',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accord',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accordion',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'accretions',\n",
       " 'accurately',\n",
       " 'accusatory',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accustomed',\n",
       " 'ace',\n",
       " 'acerbic',\n",
       " 'aces',\n",
       " 'acetone',\n",
       " 'ache',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'aching',\n",
       " 'achingly',\n",
       " 'acid',\n",
       " 'acirc',\n",
       " 'ack',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledges',\n",
       " 'acknowledging',\n",
       " 'acmes',\n",
       " 'acmots',\n",
       " 'acolytes',\n",
       " 'acorn',\n",
       " 'acoustic',\n",
       " 'acoustics',\n",
       " 'acquired',\n",
       " 'acquiring',\n",
       " 'acquisition',\n",
       " 'acrimony',\n",
       " 'acrobatic',\n",
       " 'acrobats',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'activism',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actualized',\n",
       " 'actually',\n",
       " 'acute',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adams',\n",
       " 'adamson',\n",
       " 'adapt',\n",
       " 'adaptable',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addicting',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'addled',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adele',\n",
       " 'adept',\n",
       " 'adeptly',\n",
       " 'adhd',\n",
       " 'adherence',\n",
       " 'adjectives',\n",
       " 'adjudicating',\n",
       " 'adjustment',\n",
       " 'adlai',\n",
       " 'administration',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiral',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admirers',\n",
       " 'admit',\n",
       " 'admiti',\n",
       " 'admits',\n",
       " 'admittance',\n",
       " 'admittedly',\n",
       " 'adolescence',\n",
       " 'adolescents',\n",
       " 'adopt',\n",
       " 'adorableness',\n",
       " 'adoration',\n",
       " 'adore',\n",
       " 'adored',\n",
       " 'adrenal',\n",
       " 'adrenaline',\n",
       " 'adrenalize',\n",
       " 'adrenalized',\n",
       " 'adrian',\n",
       " 'adult',\n",
       " 'adulthood',\n",
       " 'adults',\n",
       " 'advaitic',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancements',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'adversity',\n",
       " 'advertisement',\n",
       " 'advertising',\n",
       " 'adverts',\n",
       " 'advice',\n",
       " 'advised',\n",
       " 'advocate',\n",
       " 'advocating',\n",
       " 'adz',\n",
       " 'aereogramme',\n",
       " 'aerial',\n",
       " 'aeroplane',\n",
       " 'aesop',\n",
       " 'aesthete',\n",
       " 'aesthetic',\n",
       " 'aesthetically',\n",
       " 'aestheticism',\n",
       " 'aesthetics',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affectation',\n",
       " 'affecting',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affiliation',\n",
       " 'affirmation',\n",
       " 'affirmative',\n",
       " 'affirming',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afforded',\n",
       " 'affords',\n",
       " 'aficionado',\n",
       " 'afloat',\n",
       " 'aforementioned',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'afrika',\n",
       " 'afro',\n",
       " 'after',\n",
       " 'afterlife',\n",
       " 'afterman',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'afterthoughts',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agei',\n",
       " 'ageless',\n",
       " 'agenda',\n",
       " 'agendas',\n",
       " 'ages',\n",
       " 'aggravated',\n",
       " 'aggravating',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'aggro',\n",
       " 'agile',\n",
       " 'aging',\n",
       " 'agit',\n",
       " 'ago',\n",
       " 'agonizing',\n",
       " 'agony',\n",
       " 'agostino',\n",
       " 'agreat',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreed',\n",
       " 'aguayo',\n",
       " 'aguilera',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahi',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aided',\n",
       " 'aiko',\n",
       " 'ails',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aimlessly',\n",
       " 'aims',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airbrushed',\n",
       " 'airing',\n",
       " 'airplane',\n",
       " 'airplay',\n",
       " 'airs',\n",
       " 'airy',\n",
       " 'aisles',\n",
       " 'ait',\n",
       " 'aja',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akin',\n",
       " 'akon',\n",
       " 'akron',\n",
       " 'al',\n",
       " 'alabama',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alarms',\n",
       " 'alas',\n",
       " 'alaska',\n",
       " 'albarn',\n",
       " 'albatross',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'alberta',\n",
       " 'albini',\n",
       " 'albion',\n",
       " 'albulm',\n",
       " 'album',\n",
       " 'albumone',\n",
       " 'albums',\n",
       " 'albumthis',\n",
       " 'alchemists',\n",
       " 'alcoholism',\n",
       " 'alec',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alexis',\n",
       " 'alfie',\n",
       " 'alhambra',\n",
       " 'ali',\n",
       " 'alias',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alienated',\n",
       " 'alienating',\n",
       " 'alienation',\n",
       " 'alight',\n",
       " 'aligning',\n",
       " 'alike',\n",
       " 'alisa',\n",
       " 'alive',\n",
       " 'alkaline',\n",
       " 'all',\n",
       " 'allbran',\n",
       " 'alleged',\n",
       " 'allegiance',\n",
       " 'allen',\n",
       " 'allenthe',\n",
       " 'alley',\n",
       " 'alliance',\n",
       " 'allied',\n",
       " 'allien',\n",
       " 'allison',\n",
       " 'alliterative',\n",
       " 'allo',\n",
       " 'allot',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alloyed',\n",
       " 'allsimply',\n",
       " 'allure',\n",
       " 'alluring',\n",
       " 'allusions',\n",
       " 'allusive',\n",
       " 'almighty',\n",
       " 'almost',\n",
       " 'almostbombarding',\n",
       " 'almostjaheim',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'alpha',\n",
       " 'alpine',\n",
       " 'alpinisms',\n",
       " 'already',\n",
       " 'also',\n",
       " 'alsowe',\n",
       " 'alt',\n",
       " 'alter',\n",
       " 'alteration',\n",
       " 'altered',\n",
       " 'alteringly',\n",
       " 'alternate',\n",
       " 'alternately',\n",
       " 'alternating',\n",
       " 'alternative',\n",
       " 'alters',\n",
       " 'although',\n",
       " 'alto',\n",
       " 'altogether',\n",
       " 'altos',\n",
       " 'aluna',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amalgam',\n",
       " 'amalgamation',\n",
       " 'amassed',\n",
       " 'amassing',\n",
       " 'amateurish',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'amber',\n",
       " 'ambiance',\n",
       " 'ambien',\n",
       " 'ambience',\n",
       " 'ambient',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'ambition',\n",
       " 'ambitions',\n",
       " 'ambitious',\n",
       " 'ambivalence',\n",
       " 'ambivalent',\n",
       " 'amble',\n",
       " 'ambushed',\n",
       " 'amenable',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americana',\n",
       " 'americano',\n",
       " 'amerigo',\n",
       " 'ami',\n",
       " 'amiable',\n",
       " 'amicable',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'ammo',\n",
       " 'amnesiac',\n",
       " 'amniotic',\n",
       " 'amok',\n",
       " 'amon',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amor',\n",
       " 'amorphous',\n",
       " 'amos',\n",
       " 'amount',\n",
       " 'amounts',\n",
       " 'amour',\n",
       " 'amp',\n",
       " 'amped',\n",
       " 'ample',\n",
       " 'amplified',\n",
       " 'amplifiers',\n",
       " 'amplifies',\n",
       " 'amplify',\n",
       " 'amply',\n",
       " 'amputechture',\n",
       " 'amusement',\n",
       " 'amy',\n",
       " 'amygdala',\n",
       " 'an',\n",
       " 'anaemic',\n",
       " 'anaesthetising',\n",
       " 'analog',\n",
       " 'analogies',\n",
       " 'analogue',\n",
       " 'analogy',\n",
       " 'analysis',\n",
       " 'anarchy',\n",
       " 'ancestral',\n",
       " 'anchor',\n",
       " 'anchored',\n",
       " 'ancient',\n",
       " 'and',\n",
       " 'andafter',\n",
       " 'andanother',\n",
       " 'andclassic',\n",
       " 'anderson',\n",
       " 'andersson',\n",
       " 'andghostface',\n",
       " 'andi',\n",
       " 'andif',\n",
       " 'andnew',\n",
       " 'andoh',\n",
       " 'andorra',\n",
       " 'andpeople',\n",
       " 'andproof',\n",
       " 'andrea',\n",
       " 'andreas',\n",
       " 'andretti',\n",
       " 'andrew',\n",
       " 'androgynous',\n",
       " 'andronicus',\n",
       " 'andso',\n",
       " 'andthe',\n",
       " 'andthis',\n",
       " 'andy',\n",
       " 'anecdotes',\n",
       " 'angel',\n",
       " 'angelo',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'angles',\n",
       " 'anglophiles',\n",
       " 'anglophilia',\n",
       " 'angry',\n",
       " 'angst',\n",
       " 'angstful',\n",
       " 'anguished',\n",
       " 'angular',\n",
       " 'ani',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'animates',\n",
       " 'animus',\n",
       " 'anita',\n",
       " 'anjelica',\n",
       " 'ankh',\n",
       " 'ann',\n",
       " 'annie',\n",
       " 'annihilation',\n",
       " 'annotates',\n",
       " 'announcement',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annoyingly',\n",
       " 'anomalous',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'anothernice',\n",
       " 'anpales',\n",
       " 'ans',\n",
       " 'ansimple',\n",
       " 'answer',\n",
       " 'answers',\n",
       " 'ant',\n",
       " 'antarctica',\n",
       " 'ante',\n",
       " 'antecedent',\n",
       " 'antecedents',\n",
       " 'anthem',\n",
       " 'anthemic',\n",
       " 'anthemists',\n",
       " 'anthems',\n",
       " 'anthis',\n",
       " 'anthology',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'anticipated',\n",
       " 'anticipation',\n",
       " 'anticlimactic',\n",
       " 'antidote',\n",
       " 'antique',\n",
       " 'antiquities',\n",
       " 'antiseptic',\n",
       " 'antithesis',\n",
       " 'antlers',\n",
       " 'anton',\n",
       " 'antony',\n",
       " 'antwoord',\n",
       " 'anway',\n",
       " 'anxieties',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyi',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anythingi',\n",
       " 'anythinglet',\n",
       " 'anythingso',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'anywhoo',\n",
       " 'aoi',\n",
       " 'aopr',\n",
       " 'aor',\n",
       " 'aoty',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'apathetically',\n",
       " 'aperitif',\n",
       " 'apery',\n",
       " 'aperçus',\n",
       " 'apes',\n",
       " 'aphex',\n",
       " 'aping',\n",
       " 'apocalypse',\n",
       " 'apocalyptic',\n",
       " 'apollo',\n",
       " 'apologies',\n",
       " 'apology',\n",
       " 'appalachia',\n",
       " 'appallingly',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appeals',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appearances',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'appetite',\n",
       " 'appetites',\n",
       " 'applauding',\n",
       " 'applause',\n",
       " 'apple',\n",
       " 'apples',\n",
       " 'appleseed',\n",
       " 'applied',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appointments',\n",
       " 'appraisal',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciation',\n",
       " 'approach',\n",
       " 'approachable',\n",
       " 'approached',\n",
       " 'approaches',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'appropriated',\n",
       " 'appropriately',\n",
       " 'appropriating',\n",
       " 'appropriation',\n",
       " 'apr',\n",
       " 'april',\n",
       " 'aprobably',\n",
       " 'apt',\n",
       " 'aptitude',\n",
       " 'aptly',\n",
       " 'aquarium',\n",
       " 'aquemeni',\n",
       " 'ar',\n",
       " 'arab',\n",
       " 'arabesques',\n",
       " 'arbez',\n",
       " 'arbitrary',\n",
       " 'arbouretum',\n",
       " 'arc',\n",
       " 'arcade',\n",
       " 'arcadian',\n",
       " 'arcana',\n",
       " 'arcane',\n",
       " 'arch',\n",
       " 'archaeology',\n",
       " 'archaic',\n",
       " 'archandroid',\n",
       " 'architect',\n",
       " 'architecture',\n",
       " 'archive',\n",
       " 'archives',\n",
       " 'arctic',\n",
       " 'ardent',\n",
       " 'are',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'arena',\n",
       " 'arenas',\n",
       " 'aretha',\n",
       " 'argentine',\n",
       " 'argos',\n",
       " 'arguable',\n",
       " 'arguably',\n",
       " 'argue',\n",
       " 'argued',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'ariana',\n",
       " 'arid',\n",
       " 'arline',\n",
       " 'arling',\n",
       " 'arm',\n",
       " 'armada',\n",
       " 'armchair',\n",
       " 'armed',\n",
       " 'armonico',\n",
       " 'arms',\n",
       " 'armstrong',\n",
       " 'army',\n",
       " 'around',\n",
       " 'arouse',\n",
       " 'arpeggio',\n",
       " 'arrange',\n",
       " 'arranged',\n",
       " 'arrangement',\n",
       " 'arrangements',\n",
       " 'arranger',\n",
       " 'arranging',\n",
       " 'array',\n",
       " 'arrest',\n",
       " 'arrested',\n",
       " 'arresting',\n",
       " 'arrington',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrogance',\n",
       " 'arrow',\n",
       " 'arse',\n",
       " 'arsenal',\n",
       " 'arsenault',\n",
       " 'art',\n",
       " 'artful',\n",
       " 'artfully',\n",
       " 'artfulness',\n",
       " 'arthouse',\n",
       " 'arthur',\n",
       " 'articulate',\n",
       " 'articulated',\n",
       " 'artier',\n",
       " 'artifact',\n",
       " 'artifacts',\n",
       " 'artifice',\n",
       " 'artist',\n",
       " 'artiste',\n",
       " 'artistes',\n",
       " 'artistic',\n",
       " 'artistically',\n",
       " 'artistry',\n",
       " 'artists',\n",
       " 'artless',\n",
       " 'artpop',\n",
       " 'artwork',\n",
       " 'arty',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'asby',\n",
       " 'ascendance',\n",
       " 'ascent',\n",
       " 'ashanti',\n",
       " 'ashes',\n",
       " 'ashin',\n",
       " 'ashley',\n",
       " 'ashworth',\n",
       " 'asian',\n",
       " 'asiatisch',\n",
       " 'aside',\n",
       " 'asides',\n",
       " 'ask',\n",
       " 'askew',\n",
       " 'asking',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'aspirants',\n",
       " 'aspiration',\n",
       " 'aspirations',\n",
       " 'aspire',\n",
       " 'aspires',\n",
       " 'aspiring',\n",
       " 'ass',\n",
       " 'assault',\n",
       " 'assaulted',\n",
       " 'assemblage',\n",
       " 'assembled',\n",
       " 'assepultura',\n",
       " 'assertion',\n",
       " 'assertions',\n",
       " 'assertive',\n",
       " 'assertments',\n",
       " 'asserts',\n",
       " 'assess',\n",
       " 'assessment',\n",
       " 'asset',\n",
       " 'assets',\n",
       " 'assignations',\n",
       " 'assimilate',\n",
       " 'assimilation',\n",
       " 'assist',\n",
       " 'assisted',\n",
       " 'asso',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'associations',\n",
       " 'associative',\n",
       " 'assorted',\n",
       " 'assortment',\n",
       " 'assuage',\n",
       " 'assume',\n",
       " 'assumes',\n",
       " 'assuming',\n",
       " 'assurance',\n",
       " 'assured',\n",
       " 'asthis',\n",
       " 'astonishes',\n",
       " 'astonishing',\n",
       " 'astonishingly',\n",
       " 'astouding',\n",
       " 'astounded',\n",
       " 'astounding',\n",
       " 'astoundingly',\n",
       " 'astounds',\n",
       " 'astral',\n",
       " 'astronauts',\n",
       " 'astrophysics',\n",
       " 'asunder',\n",
       " 'asundoubtedly',\n",
       " 'at',\n",
       " 'athe',\n",
       " 'atheist',\n",
       " 'athis',\n",
       " 'athlete',\n",
       " 'atilde',\n",
       " 'atkins',\n",
       " 'atlanta',\n",
       " 'atlantis',\n",
       " 'atlas',\n",
       " 'atleast',\n",
       " 'atmosphere',\n",
       " 'atmospheric',\n",
       " 'atmospherically',\n",
       " 'atmospherics',\n",
       " 'atomic',\n",
       " 'atoms',\n",
       " 'atonement',\n",
       " 'atoning',\n",
       " 'atr',\n",
       " 'atrocious',\n",
       " 'atrophied',\n",
       " 'attached',\n",
       " 'attachment',\n",
       " 'attack',\n",
       " 'attacks',\n",
       " 'attempt',\n",
       " 'attempting',\n",
       " 'attempts',\n",
       " 'attendant',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attentions',\n",
       " 'attentive',\n",
       " 'attentively',\n",
       " 'attest',\n",
       " 'attitude',\n",
       " 'attitudes',\n",
       " 'attitudinal',\n",
       " 'attract',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'attributes',\n",
       " 'atyes',\n",
       " 'atypical',\n",
       " 'atypically',\n",
       " 'aubert',\n",
       " 'aubrey',\n",
       " 'audacious',\n",
       " 'audacity',\n",
       " 'audible',\n",
       " 'audience',\n",
       " 'audiences',\n",
       " 'audio',\n",
       " 'auditioning',\n",
       " 'audoditacker',\n",
       " 'auerbach',\n",
       " 'aug',\n",
       " 'aughts',\n",
       " 'augmentations',\n",
       " 'august',\n",
       " 'augustine',\n",
       " 'augé',\n",
       " 'auidence',\n",
       " 'aura',\n",
       " 'aural',\n",
       " 'aurally',\n",
       " 'aussie',\n",
       " 'austere',\n",
       " 'austerity',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'austria',\n",
       " 'autechre',\n",
       " 'authentic',\n",
       " 'authentically',\n",
       " 'authenticity',\n",
       " 'author',\n",
       " 'authored',\n",
       " 'authority',\n",
       " 'authorized',\n",
       " 'auto',\n",
       " 'autobahn',\n",
       " 'autobiography',\n",
       " 'automatically',\n",
       " 'autopilot',\n",
       " 'autotuned',\n",
       " 'autumn',\n",
       " 'autumnal',\n",
       " 'available',\n",
       " 'avalanche',\n",
       " 'avanessian',\n",
       " 'avant',\n",
       " 'avary',\n",
       " 'avec',\n",
       " 'avenue',\n",
       " 'avenues',\n",
       " 'aveo',\n",
       " 'average',\n",
       " 'averages',\n",
       " 'averse',\n",
       " 'avett',\n",
       " 'avi',\n",
       " 'avoid',\n",
       " 'avoidance',\n",
       " 'avoiding',\n",
       " 'avoids',\n",
       " 'avowed',\n",
       " 'avril',\n",
       " 'awaited',\n",
       " 'awake',\n",
       " 'award',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'away',\n",
       " 'awayby',\n",
       " 'aways',\n",
       " 'awe',\n",
       " 'awesome',\n",
       " 'awesomedon',\n",
       " 'awesomely',\n",
       " 'awesomeness',\n",
       " 'awful',\n",
       " 'awfully',\n",
       " 'awhat',\n",
       " 'awhen',\n",
       " 'awkward',\n",
       " 'awkwardly',\n",
       " 'awkwardness',\n",
       " 'awry',\n",
       " 'awsome',\n",
       " 'aww',\n",
       " 'axe',\n",
       " 'axemen',\n",
       " 'axis',\n",
       " 'axl',\n",
       " 'ayler',\n",
       " 'azalea',\n",
       " 'azteca',\n",
       " 'ba',\n",
       " 'babble',\n",
       " 'babelfished',\n",
       " 'babes',\n",
       " 'baby',\n",
       " 'bacaroo',\n",
       " 'bach',\n",
       " 'bacharach',\n",
       " 'bachmann',\n",
       " 'back',\n",
       " 'backdrop',\n",
       " 'backed',\n",
       " 'background',\n",
       " 'backing',\n",
       " 'backpacker',\n",
       " 'backroads',\n",
       " 'backs',\n",
       " 'backseat',\n",
       " 'backside',\n",
       " 'backsliding',\n",
       " 'backspacer',\n",
       " 'backstory',\n",
       " 'backup',\n",
       " 'backward',\n",
       " 'backwards',\n",
       " 'backwoods',\n",
       " 'backwoodsman',\n",
       " 'backyard',\n",
       " 'bad',\n",
       " 'bada',\n",
       " 'baddest',\n",
       " 'badly',\n",
       " 'badn',\n",
       " 'badpontos',\n",
       " 'badu',\n",
       " 'baffle',\n",
       " 'baffling',\n",
       " 'bafflingly',\n",
       " 'bag',\n",
       " 'baggage',\n",
       " 'baggy',\n",
       " 'bagshaw',\n",
       " 'bailey',\n",
       " 'baiting',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a columns variable that is a list of all column names\n",
    "columns = list(dtm_df)\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abilities',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'above',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'acceptable',\n",
       " 'accessible',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accurately',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'adaptable',\n",
       " 'adept',\n",
       " 'adeptly',\n",
       " 'adherence',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiration',\n",
       " 'adored',\n",
       " 'advanced',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'adventurous',\n",
       " 'advice',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affirmation',\n",
       " 'affirmative',\n",
       " 'affordable',\n",
       " 'afloat',\n",
       " 'agile',\n",
       " 'agreeable',\n",
       " 'allure',\n",
       " 'alluring',\n",
       " 'almighty',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'ambitious',\n",
       " 'amenable',\n",
       " 'amiable',\n",
       " 'amicable',\n",
       " 'amour',\n",
       " 'ample',\n",
       " 'amply',\n",
       " 'amusement',\n",
       " 'angel',\n",
       " 'animated',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appreciation',\n",
       " 'appropriate',\n",
       " 'apt',\n",
       " 'aptitude',\n",
       " 'aptly',\n",
       " 'ardent',\n",
       " 'arresting',\n",
       " 'articulate',\n",
       " 'aspiration',\n",
       " 'aspirations',\n",
       " 'assertions',\n",
       " 'assertive',\n",
       " 'asset',\n",
       " 'assurance',\n",
       " 'astonishing',\n",
       " 'astonishingly',\n",
       " 'astounded',\n",
       " 'astounding',\n",
       " 'astoundingly',\n",
       " 'attentive',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'authentic',\n",
       " 'award',\n",
       " 'awe',\n",
       " 'awesome',\n",
       " 'awesomely',\n",
       " 'awesomeness',\n",
       " 'balanced',\n",
       " 'bargain',\n",
       " 'basic',\n",
       " 'beacon',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'befitting',\n",
       " 'beloved',\n",
       " 'benefit',\n",
       " 'benefits',\n",
       " 'benevolence',\n",
       " 'benign',\n",
       " 'better',\n",
       " 'blessing',\n",
       " 'bliss',\n",
       " 'blissful',\n",
       " 'blissfully',\n",
       " 'blithe',\n",
       " 'bold',\n",
       " 'boldly',\n",
       " 'boldness',\n",
       " 'bonus',\n",
       " 'boom',\n",
       " 'booming',\n",
       " 'boost',\n",
       " 'boundless',\n",
       " 'brains',\n",
       " 'brainy',\n",
       " 'brave',\n",
       " 'bravery',\n",
       " 'breakthrough',\n",
       " 'breathtaking',\n",
       " 'breathtakingly',\n",
       " 'bright',\n",
       " 'brightness',\n",
       " 'brilliance',\n",
       " 'brilliant',\n",
       " 'brilliantly',\n",
       " 'brisk',\n",
       " 'broad',\n",
       " 'bull',\n",
       " 'bullish',\n",
       " 'buoyant',\n",
       " 'calm',\n",
       " 'candid',\n",
       " 'capable',\n",
       " 'capably',\n",
       " 'captivating',\n",
       " 'carefree',\n",
       " 'careful',\n",
       " 'catchy',\n",
       " 'celebrated',\n",
       " 'celebration',\n",
       " 'celebrity',\n",
       " 'champ',\n",
       " 'charismatic',\n",
       " 'charm',\n",
       " 'charming',\n",
       " 'charmingly',\n",
       " 'chaste',\n",
       " 'cheer',\n",
       " 'cherished',\n",
       " 'chic',\n",
       " 'civil',\n",
       " 'clarity',\n",
       " 'classic',\n",
       " 'clean',\n",
       " 'clearer',\n",
       " 'clearly',\n",
       " 'clever',\n",
       " 'cogent',\n",
       " 'coherence',\n",
       " 'coherent',\n",
       " 'cohesion',\n",
       " 'cohesive',\n",
       " 'colorful',\n",
       " 'colossal',\n",
       " 'comeback',\n",
       " 'comfortable',\n",
       " 'comfortably',\n",
       " 'comforting',\n",
       " 'commendable',\n",
       " 'commitment',\n",
       " 'compact',\n",
       " 'compelling',\n",
       " 'competence',\n",
       " 'competent',\n",
       " 'complement',\n",
       " 'complimentary',\n",
       " 'comprehensive',\n",
       " 'compromise',\n",
       " 'conceivable',\n",
       " 'concrete',\n",
       " 'confidence',\n",
       " 'confident',\n",
       " 'congratulations',\n",
       " 'conscience',\n",
       " 'conscientious',\n",
       " 'consistent',\n",
       " 'constructive',\n",
       " 'consummate',\n",
       " 'content',\n",
       " 'contentment',\n",
       " 'continuity',\n",
       " 'convenient',\n",
       " 'conviction',\n",
       " 'convincing',\n",
       " 'convincingly',\n",
       " 'cornerstone',\n",
       " 'correct',\n",
       " 'courage',\n",
       " 'courtesy',\n",
       " 'cozy',\n",
       " 'craving',\n",
       " 'creative',\n",
       " 'credence',\n",
       " 'credible',\n",
       " 'crisp',\n",
       " 'cute',\n",
       " 'dance',\n",
       " 'daring',\n",
       " 'daringly',\n",
       " 'dazzling',\n",
       " 'deal',\n",
       " 'dear',\n",
       " 'decent',\n",
       " 'dedicated',\n",
       " 'definite',\n",
       " 'definitive',\n",
       " 'definitively',\n",
       " 'deft',\n",
       " 'delectable',\n",
       " 'delicate',\n",
       " 'delicious',\n",
       " 'delight',\n",
       " 'delighted',\n",
       " 'delightfully',\n",
       " 'deserving',\n",
       " 'desire',\n",
       " 'destined',\n",
       " 'determination',\n",
       " 'devoted',\n",
       " 'devotion',\n",
       " 'devout',\n",
       " 'dexterity',\n",
       " 'dexterous',\n",
       " 'dignified',\n",
       " 'dignity',\n",
       " 'diligent',\n",
       " 'discerning',\n",
       " 'discreet',\n",
       " 'discriminating',\n",
       " 'distinct',\n",
       " 'distinction',\n",
       " 'distinctive',\n",
       " 'distinguished',\n",
       " 'divine',\n",
       " 'dodge',\n",
       " 'dream',\n",
       " 'dreamland',\n",
       " 'dreams',\n",
       " 'dreamy',\n",
       " 'drive',\n",
       " 'driven',\n",
       " 'dynamic',\n",
       " 'eager',\n",
       " 'eagerness',\n",
       " 'earnest',\n",
       " 'earnestly',\n",
       " 'earnestness',\n",
       " 'ease',\n",
       " 'easy',\n",
       " 'easygoing',\n",
       " 'ebullience',\n",
       " 'ebullient',\n",
       " 'eclectic',\n",
       " 'economical',\n",
       " 'ecstasy',\n",
       " 'ecstatic',\n",
       " 'educated',\n",
       " 'effective',\n",
       " 'effectiveness',\n",
       " 'efficiency',\n",
       " 'efficient',\n",
       " 'effortless',\n",
       " 'effortlessly',\n",
       " 'elan',\n",
       " 'elegance',\n",
       " 'elegant',\n",
       " 'elegantly',\n",
       " 'elevated',\n",
       " 'elite',\n",
       " 'eloquence',\n",
       " 'eloquent',\n",
       " 'empowerment',\n",
       " 'enchanting',\n",
       " 'encouraging',\n",
       " 'endearing',\n",
       " 'endorsement',\n",
       " 'enduring',\n",
       " 'energetic',\n",
       " 'engaging',\n",
       " 'engrossing',\n",
       " 'enhanced',\n",
       " 'enjoyable',\n",
       " 'enjoyably',\n",
       " 'enjoyment',\n",
       " 'entertaining',\n",
       " 'enthusiasm',\n",
       " 'enthusiastic',\n",
       " 'enthusiastically',\n",
       " 'enticing',\n",
       " 'entrancing',\n",
       " 'enviable',\n",
       " 'epic',\n",
       " 'especially',\n",
       " 'essential',\n",
       " 'established',\n",
       " 'eternity',\n",
       " 'ethical',\n",
       " 'euphoric',\n",
       " 'even',\n",
       " 'everlasting',\n",
       " 'evocative',\n",
       " 'exalted',\n",
       " 'exceedingly',\n",
       " 'excellence',\n",
       " 'excellent',\n",
       " 'excellently',\n",
       " 'exceptional',\n",
       " 'exceptionally',\n",
       " 'excited',\n",
       " 'excitement',\n",
       " 'exciting',\n",
       " 'excitingly',\n",
       " 'exclusive',\n",
       " 'excusable',\n",
       " 'exhaustive',\n",
       " 'exhaustively',\n",
       " 'exhilarating',\n",
       " 'expansive',\n",
       " 'experienced',\n",
       " 'expert',\n",
       " 'expertly',\n",
       " 'explicit',\n",
       " 'expressive',\n",
       " 'exquisite',\n",
       " 'exquisitely',\n",
       " 'extraordinary',\n",
       " 'exuberant',\n",
       " 'fair',\n",
       " 'fairly',\n",
       " 'fairness',\n",
       " 'faith',\n",
       " 'faithful',\n",
       " 'faithfully',\n",
       " 'fame',\n",
       " 'famed',\n",
       " 'famous',\n",
       " 'famously',\n",
       " 'fancy',\n",
       " 'fantastic',\n",
       " 'fantastically',\n",
       " 'fantasy',\n",
       " 'fascinating',\n",
       " 'fascinatingly',\n",
       " 'fascination',\n",
       " 'fashionable',\n",
       " 'fashionably',\n",
       " 'favor',\n",
       " 'favorable',\n",
       " 'favorite',\n",
       " 'favour',\n",
       " 'fearless',\n",
       " 'fearlessly',\n",
       " 'feat',\n",
       " 'feisty',\n",
       " 'fertile',\n",
       " 'fervent',\n",
       " 'fidelity',\n",
       " 'fiery',\n",
       " 'fine',\n",
       " 'finely',\n",
       " 'fit',\n",
       " 'fitting',\n",
       " 'flair',\n",
       " 'flame',\n",
       " 'flattering',\n",
       " 'flawless',\n",
       " 'flawlessly',\n",
       " 'flexible',\n",
       " 'flourish',\n",
       " 'fond',\n",
       " 'fondness',\n",
       " 'foremost',\n",
       " 'forgiving',\n",
       " 'fragrant',\n",
       " 'frank',\n",
       " 'free',\n",
       " 'freedom',\n",
       " 'freedoms',\n",
       " 'fresh',\n",
       " 'friend',\n",
       " 'friendly',\n",
       " 'friends',\n",
       " 'friendship',\n",
       " 'fruitful',\n",
       " 'fulfillment',\n",
       " 'fun',\n",
       " 'functional',\n",
       " 'funny',\n",
       " 'gain',\n",
       " 'gem',\n",
       " 'gems',\n",
       " 'generosity',\n",
       " 'generous',\n",
       " 'genial',\n",
       " 'genius',\n",
       " 'gentle',\n",
       " 'genuine',\n",
       " 'giddy',\n",
       " 'gifted',\n",
       " 'glad',\n",
       " 'glee',\n",
       " 'gleeful',\n",
       " 'gleefully',\n",
       " 'glimmer',\n",
       " 'glimmering',\n",
       " 'glisten',\n",
       " 'glistening',\n",
       " 'glitter',\n",
       " 'glorious',\n",
       " 'gloriously',\n",
       " 'glory',\n",
       " 'glossy',\n",
       " 'godlike',\n",
       " 'gold',\n",
       " 'golden',\n",
       " 'good',\n",
       " 'goodness',\n",
       " 'goodwill',\n",
       " 'gorgeous',\n",
       " 'gorgeously',\n",
       " 'grace',\n",
       " 'graceful',\n",
       " 'gracefully',\n",
       " 'gracious',\n",
       " 'grand',\n",
       " 'grandeur',\n",
       " 'gratification',\n",
       " 'gratifying',\n",
       " 'great',\n",
       " 'greatest',\n",
       " 'greatness',\n",
       " 'grit',\n",
       " 'groundbreaking',\n",
       " 'guarantee',\n",
       " 'guidance',\n",
       " 'gusto',\n",
       " 'gutsy',\n",
       " 'halcyon',\n",
       " 'handsome',\n",
       " 'handy',\n",
       " 'happily',\n",
       " 'happiness',\n",
       " 'happy',\n",
       " 'hardy',\n",
       " 'harmless',\n",
       " 'harmonious',\n",
       " 'harmony',\n",
       " 'haven',\n",
       " 'heady',\n",
       " 'healthy',\n",
       " 'heart',\n",
       " 'heartening',\n",
       " 'heartfelt',\n",
       " 'heartily',\n",
       " 'heartwarming',\n",
       " 'heaven',\n",
       " 'heavenly',\n",
       " 'help',\n",
       " 'helpful',\n",
       " 'hero',\n",
       " 'heroic',\n",
       " 'highlight',\n",
       " 'hilarious',\n",
       " 'hilariousness',\n",
       " 'hilarity',\n",
       " 'holy',\n",
       " 'homage',\n",
       " 'honest',\n",
       " 'honestly',\n",
       " 'honesty',\n",
       " 'honeymoon',\n",
       " 'honor',\n",
       " 'hope',\n",
       " 'hopeful',\n",
       " 'hopefully',\n",
       " 'hopes',\n",
       " 'hot',\n",
       " 'humane',\n",
       " 'humanity',\n",
       " 'humankind',\n",
       " 'humility',\n",
       " 'humorous',\n",
       " 'humorously',\n",
       " 'humour',\n",
       " 'ideal',\n",
       " 'idealism',\n",
       " 'idol',\n",
       " 'idolized',\n",
       " 'illuminating',\n",
       " 'illustrious',\n",
       " 'imaginative',\n",
       " 'immaculate',\n",
       " 'immaculately',\n",
       " 'impassioned',\n",
       " 'impeccable',\n",
       " 'impeccably',\n",
       " 'imperial',\n",
       " 'impervious',\n",
       " 'impetus',\n",
       " 'importance',\n",
       " 'important',\n",
       " 'importantly',\n",
       " 'impression',\n",
       " 'impressions',\n",
       " 'impressive',\n",
       " 'impressively',\n",
       " 'improved',\n",
       " 'improvement',\n",
       " 'incisive',\n",
       " 'inclination',\n",
       " 'inclined',\n",
       " 'incredible',\n",
       " 'incredibly',\n",
       " 'indebted',\n",
       " 'indelible',\n",
       " 'independence',\n",
       " 'independent',\n",
       " 'indescribable',\n",
       " 'indestructible',\n",
       " 'indispensable',\n",
       " 'individuality',\n",
       " 'indulgence',\n",
       " 'indulgent',\n",
       " 'influential',\n",
       " 'ingenious',\n",
       " 'ingenuity',\n",
       " 'ingratiating',\n",
       " 'innocence',\n",
       " 'innocent',\n",
       " 'innocuous',\n",
       " 'innovation',\n",
       " 'innovative',\n",
       " 'inoffensive',\n",
       " 'insight',\n",
       " 'insightful',\n",
       " 'insistence',\n",
       " 'insistent',\n",
       " 'insistently',\n",
       " 'inspiration',\n",
       " 'inspirational',\n",
       " 'inspiring',\n",
       " 'instrumental',\n",
       " 'intact',\n",
       " 'intelligence',\n",
       " 'intelligent',\n",
       " 'interest',\n",
       " 'interested',\n",
       " 'interesting',\n",
       " 'interests',\n",
       " 'intimacy',\n",
       " 'intimate',\n",
       " 'intricate',\n",
       " 'intrigue',\n",
       " 'intriguing',\n",
       " 'intuitive',\n",
       " 'inventive',\n",
       " 'invigorating',\n",
       " 'invincibility',\n",
       " 'irrefutably',\n",
       " 'irresistible',\n",
       " 'irresistibly',\n",
       " 'jaunty',\n",
       " 'joke',\n",
       " 'jovial',\n",
       " 'joy',\n",
       " 'joyful',\n",
       " 'joyfully',\n",
       " 'joyless',\n",
       " 'joyous',\n",
       " 'joyously',\n",
       " 'judicious',\n",
       " 'just',\n",
       " 'justice',\n",
       " 'justifiable',\n",
       " 'justly',\n",
       " 'keen',\n",
       " 'keenly',\n",
       " 'kind',\n",
       " 'kiss',\n",
       " 'large',\n",
       " 'laudably',\n",
       " 'lavish',\n",
       " 'lavishly',\n",
       " 'leading',\n",
       " 'lean',\n",
       " 'learned',\n",
       " 'learning',\n",
       " 'legendary',\n",
       " 'legitimacy',\n",
       " 'legitimate',\n",
       " 'legitimately',\n",
       " 'levity',\n",
       " 'liberal',\n",
       " 'liberally',\n",
       " 'liberation',\n",
       " 'liberty',\n",
       " 'lifelong',\n",
       " 'light',\n",
       " 'likable',\n",
       " 'literate',\n",
       " 'live',\n",
       " 'lively',\n",
       " 'lofty',\n",
       " 'logical',\n",
       " 'lovable',\n",
       " 'love',\n",
       " 'lovely',\n",
       " 'lover',\n",
       " 'loyal',\n",
       " 'loyalty',\n",
       " 'lucid',\n",
       " 'luck',\n",
       " 'luckily',\n",
       " 'lucky',\n",
       " 'luminous',\n",
       " 'lush',\n",
       " 'luxurious',\n",
       " 'lyrical',\n",
       " 'magic',\n",
       " 'magical',\n",
       " 'magnetic',\n",
       " 'magnificence',\n",
       " 'magnificent',\n",
       " 'magnificently',\n",
       " 'majestic',\n",
       " 'majesty',\n",
       " 'manifest',\n",
       " 'marvel',\n",
       " 'marvellous',\n",
       " 'marvelous',\n",
       " 'marvelously',\n",
       " 'marvels',\n",
       " 'master',\n",
       " 'masterful',\n",
       " 'masterfully',\n",
       " 'masterpiece',\n",
       " 'masterpieces',\n",
       " 'masters',\n",
       " 'mastery',\n",
       " 'mature',\n",
       " 'maturity',\n",
       " 'meaningful',\n",
       " 'meek',\n",
       " 'mellow',\n",
       " 'memorable',\n",
       " 'mentor',\n",
       " 'mercifully',\n",
       " 'mercy',\n",
       " 'merit',\n",
       " 'merry',\n",
       " 'mesmerizing',\n",
       " 'meticulous',\n",
       " 'meticulously',\n",
       " 'might',\n",
       " 'mightily',\n",
       " 'mighty',\n",
       " 'mild',\n",
       " 'mindful',\n",
       " 'miracle',\n",
       " 'moderate',\n",
       " 'modern',\n",
       " 'modest',\n",
       " 'monumental',\n",
       " 'moral',\n",
       " 'motivated',\n",
       " 'moving',\n",
       " 'myriad',\n",
       " 'natural',\n",
       " 'naturally',\n",
       " 'neat',\n",
       " 'neatly',\n",
       " 'necessarily',\n",
       " 'necessary',\n",
       " 'nice',\n",
       " 'nimble',\n",
       " 'noble',\n",
       " 'normal',\n",
       " 'notable',\n",
       " 'noteworthy',\n",
       " 'noticeable',\n",
       " 'nourishing',\n",
       " 'novel',\n",
       " 'nurturing',\n",
       " 'oasis',\n",
       " 'objectively',\n",
       " 'offbeat',\n",
       " 'okay',\n",
       " 'open',\n",
       " 'openly',\n",
       " 'opportunity',\n",
       " 'optimism',\n",
       " 'optimistic',\n",
       " 'opulent',\n",
       " 'original',\n",
       " 'originality',\n",
       " 'outstanding',\n",
       " 'painstakingly',\n",
       " 'palatable',\n",
       " 'paradise',\n",
       " 'paramount',\n",
       " 'passion',\n",
       " 'passionate',\n",
       " 'patience',\n",
       " 'patient',\n",
       " 'patiently',\n",
       " 'peace',\n",
       " 'peaceable',\n",
       " 'peaceful',\n",
       " 'peerless',\n",
       " 'penitent',\n",
       " 'perfect',\n",
       " 'perfection',\n",
       " 'perfectly',\n",
       " 'perseverance',\n",
       " 'personality',\n",
       " 'persuasive',\n",
       " 'phenomenal',\n",
       " 'piety',\n",
       " 'pinnacle',\n",
       " 'pithy',\n",
       " 'placid',\n",
       " 'plain',\n",
       " 'playful',\n",
       " 'playfully',\n",
       " 'pleasant',\n",
       " 'pleasantly',\n",
       " 'pleased',\n",
       " 'pleasing',\n",
       " 'pleasure',\n",
       " 'pledges',\n",
       " 'plentiful',\n",
       " 'plush',\n",
       " 'poetic',\n",
       " 'poignant',\n",
       " 'poise',\n",
       " 'poised',\n",
       " 'polished',\n",
       " 'polite',\n",
       " 'popular',\n",
       " 'popularity',\n",
       " 'positive',\n",
       " 'positively',\n",
       " 'potent',\n",
       " 'potential',\n",
       " 'powerful',\n",
       " 'powerfully',\n",
       " 'praise',\n",
       " 'preaching',\n",
       " 'precious',\n",
       " 'precise',\n",
       " 'precisely',\n",
       " 'precision',\n",
       " 'preference',\n",
       " 'premier',\n",
       " 'prepared',\n",
       " 'prettily',\n",
       " 'pretty',\n",
       " 'pride',\n",
       " 'principle',\n",
       " 'privileged',\n",
       " 'pro',\n",
       " 'prodigious',\n",
       " 'prodigy',\n",
       " 'proficient',\n",
       " 'profit',\n",
       " 'profound',\n",
       " 'profoundly',\n",
       " 'progress',\n",
       " 'progressive',\n",
       " 'prolific',\n",
       " 'prominent',\n",
       " 'promise',\n",
       " 'promising',\n",
       " 'proper',\n",
       " 'properly',\n",
       " 'prospect',\n",
       " 'prosperity',\n",
       " 'proud',\n",
       " 'providence',\n",
       " 'prowess',\n",
       " 'pure',\n",
       " 'purity',\n",
       " 'purposeful',\n",
       " 'quaint',\n",
       " 'radiance',\n",
       " 'radiant',\n",
       " 'rapport',\n",
       " 'rapture',\n",
       " 'rational',\n",
       " 'readily',\n",
       " 'ready',\n",
       " 'reaffirmation',\n",
       " 'real',\n",
       " 'realistic',\n",
       " 'realistically',\n",
       " 'reason',\n",
       " 'reasonable',\n",
       " 'reasonably',\n",
       " 'recognition',\n",
       " 'recommendation',\n",
       " 'recommended',\n",
       " 'redeeming',\n",
       " 'redemption',\n",
       " 'refined',\n",
       " 'refinement',\n",
       " 'refreshing',\n",
       " 'regard',\n",
       " 'rehabilitation',\n",
       " 'reinforcement',\n",
       " 'rejoicing',\n",
       " 'relaxed',\n",
       " 'relevance',\n",
       " 'relevant',\n",
       " 'reliable',\n",
       " 'reliably',\n",
       " 'relief',\n",
       " 'remarkable',\n",
       " 'remarkably',\n",
       " 'reminiscent',\n",
       " 'renowned',\n",
       " 'repair',\n",
       " 'rescue',\n",
       " 'resilient',\n",
       " 'resolute',\n",
       " 'resolved',\n",
       " 'resounding',\n",
       " 'respect',\n",
       " 'respectable',\n",
       " 'respectful',\n",
       " 'respectfully',\n",
       " 'respite',\n",
       " 'responsive',\n",
       " 'restraint',\n",
       " 'revel',\n",
       " 'revelation',\n",
       " 'reverence',\n",
       " 'reverent',\n",
       " 'revival',\n",
       " 'revolution',\n",
       " 'rewarding',\n",
       " 'rich',\n",
       " 'riches',\n",
       " 'richly',\n",
       " 'richness',\n",
       " 'right',\n",
       " 'righteous',\n",
       " 'righteously',\n",
       " 'rightful',\n",
       " 'rightfully',\n",
       " 'rights',\n",
       " 'ripe',\n",
       " 'robust',\n",
       " 'rousing',\n",
       " 'sacred',\n",
       " 'safe',\n",
       " 'sage',\n",
       " 'saint',\n",
       " 'sanctuary',\n",
       " 'sanguine',\n",
       " 'sanity',\n",
       " 'satisfaction',\n",
       " 'satisfactory',\n",
       " 'satisfying',\n",
       " 'savvy',\n",
       " 'seamless',\n",
       " 'seasoned',\n",
       " 'secure',\n",
       " 'securely',\n",
       " 'seductive',\n",
       " 'semblance',\n",
       " 'sensation',\n",
       " 'sensational',\n",
       " 'sensations',\n",
       " 'sense',\n",
       " 'sensible',\n",
       " 'sensibly',\n",
       " 'sensitive',\n",
       " 'sensitivity',\n",
       " 'sentiment',\n",
       " 'sentiments',\n",
       " 'settle',\n",
       " 'sexy',\n",
       " 'shiny',\n",
       " 'significance',\n",
       " 'significant',\n",
       " 'simple',\n",
       " 'simplicity',\n",
       " 'sincere',\n",
       " 'sincerely',\n",
       " 'sincerity',\n",
       " 'skill',\n",
       " 'skilled',\n",
       " 'skillful',\n",
       " 'skillfully',\n",
       " 'sleek',\n",
       " 'slender',\n",
       " 'slim',\n",
       " 'smart',\n",
       " 'smarter',\n",
       " 'smartest',\n",
       " 'smartly',\n",
       " 'smile',\n",
       " 'smiling',\n",
       " 'smooth',\n",
       " 'solid',\n",
       " 'sophisticated',\n",
       " 'sound',\n",
       " 'spacious',\n",
       " 'sparing',\n",
       " 'sparingly',\n",
       " 'sparkling',\n",
       " 'special',\n",
       " 'spectacular',\n",
       " 'spectacularly',\n",
       " 'spirit',\n",
       " 'spirited',\n",
       " 'spiritual',\n",
       " 'splendid',\n",
       " 'splendidly',\n",
       " 'splendor',\n",
       " 'sprightly',\n",
       " 'squarely',\n",
       " 'stability',\n",
       " 'stable',\n",
       " 'star',\n",
       " 'stars',\n",
       " 'stately',\n",
       " 'staunch',\n",
       " 'steadfast',\n",
       " 'steadfastly',\n",
       " 'steady',\n",
       " 'stellar',\n",
       " 'stimulating',\n",
       " 'stirring',\n",
       " 'straight',\n",
       " 'straightforward',\n",
       " 'streamlined',\n",
       " 'stride',\n",
       " 'strides',\n",
       " 'striking',\n",
       " 'strikingly',\n",
       " 'striving',\n",
       " 'strong',\n",
       " 'studious',\n",
       " 'stunned',\n",
       " 'stunning',\n",
       " 'stunningly',\n",
       " 'sturdy',\n",
       " 'stylish',\n",
       " 'sublime',\n",
       " 'substantial',\n",
       " 'substantially',\n",
       " 'substantive',\n",
       " 'subtle',\n",
       " 'success',\n",
       " 'successful',\n",
       " 'successfully',\n",
       " 'sufficient',\n",
       " 'sufficiently',\n",
       " 'suggestions',\n",
       " 'suitable',\n",
       " 'sumptuous',\n",
       " 'sunny',\n",
       " 'super',\n",
       " 'superb',\n",
       " 'superbly',\n",
       " 'superior',\n",
       " 'superlative',\n",
       " 'support',\n",
       " 'supreme',\n",
       " 'sure',\n",
       " 'surge',\n",
       " 'surging',\n",
       " 'survival',\n",
       " 'survivor',\n",
       " 'sustainable',\n",
       " 'sustained',\n",
       " 'sweeping',\n",
       " 'sweet',\n",
       " 'sweetheart',\n",
       " 'sweetly',\n",
       " 'sweetness',\n",
       " 'swift',\n",
       " 'talent',\n",
       " 'talented',\n",
       " 'taste',\n",
       " 'tender',\n",
       " 'tenderly',\n",
       " 'tenderness',\n",
       " 'terrific',\n",
       " 'terrifically',\n",
       " 'thankfully',\n",
       " 'thorough',\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new variable that contains only column names that are in our postive words list\n",
    "pos_columns = [word for word in columns if word in positive_words]\n",
    "pos_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>above</th>\n",
       "      <th>abundance</th>\n",
       "      <th>abundant</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>accessible</th>\n",
       "      <th>acclaim</th>\n",
       "      <th>acclaimed</th>\n",
       "      <th>...</th>\n",
       "      <th>wonderous</th>\n",
       "      <th>worth</th>\n",
       "      <th>worthwhile</th>\n",
       "      <th>worthy</th>\n",
       "      <th>wow</th>\n",
       "      <th>wry</th>\n",
       "      <th>yearning</th>\n",
       "      <th>youthful</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5001 rows × 1119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abilities  ability  able  above  abundance  abundant  acceptable  \\\n",
       "0             0        0     0      0          0         0           0   \n",
       "1             0        0     0      0          0         0           0   \n",
       "2             0        0     0      0          0         0           0   \n",
       "3             0        0     0      0          0         0           0   \n",
       "4             0        0     0      0          0         0           0   \n",
       "...         ...      ...   ...    ...        ...       ...         ...   \n",
       "4996          0        0     0      0          0         0           0   \n",
       "4997          0        0     0      0          0         0           0   \n",
       "4998          0        0     0      0          0         0           0   \n",
       "4999          0        0     0      0          0         0           0   \n",
       "5000          0        0     0      0          0         0           0   \n",
       "\n",
       "      accessible  acclaim  acclaimed  ...  wonderous  worth  worthwhile  \\\n",
       "0              0        0          0  ...          0      0           0   \n",
       "1              0        0          0  ...          0      0           0   \n",
       "2              0        0          0  ...          0      0           0   \n",
       "3              0        0          0  ...          0      0           0   \n",
       "4              0        0          0  ...          0      0           0   \n",
       "...          ...      ...        ...  ...        ...    ...         ...   \n",
       "4996           0        0          0  ...          0      0           0   \n",
       "4997           0        0          0  ...          0      0           0   \n",
       "4998           0        0          0  ...          0      0           0   \n",
       "4999           0        0          0  ...          0      0           0   \n",
       "5000           0        0          0  ...          0      0           0   \n",
       "\n",
       "      worthy  wow  wry  yearning  youthful  zeal  zest  \n",
       "0          0    0    0         0         0     0     0  \n",
       "1          0    0    0         0         0     0     0  \n",
       "2          0    0    0         0         0     0     0  \n",
       "3          0    0    0         0         0     0     0  \n",
       "4          0    0    0         0         0     0     0  \n",
       "...      ...  ...  ...       ...       ...   ...   ...  \n",
       "4996       0    0    0         0         0     0     0  \n",
       "4997       0    0    0         0         0     0     0  \n",
       "4998       0    0    0         0         0     0     0  \n",
       "4999       0    0    0         0         0     0     0  \n",
       "5000       0    0    0         0         0     0     0  \n",
       "\n",
       "[5001 rows x 1119 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dtm from our dtm_df that keeps only positive sentiment columns\n",
    "dtm_pos = dtm_df[pos_columns]\n",
    "dtm_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-1dd0ae102fe3>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dtm_pos['pos_count'] = dtm_pos.sum(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       2\n",
       "       ..\n",
       "4996    0\n",
       "4997    3\n",
       "4998    2\n",
       "4999    1\n",
       "5000    5\n",
       "Name: pos_count, Length: 5001, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count the number of positive words for each document\n",
    "dtm_pos['pos_count'] = dtm_pos.sum(axis=1)\n",
    "#dtm_pos.drop('pos_count',axis=1, inplace=True)\n",
    "dtm_pos['pos_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "1. Do the same for negative words.  \n",
    "2. Calculate the proportion of negative and positive words for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-8529c9965bc9>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dtm_neg['neg_count'] = dtm_neg.sum(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       3\n",
       "2       1\n",
       "3       1\n",
       "4       4\n",
       "       ..\n",
       "4996    3\n",
       "4997    0\n",
       "4998    0\n",
       "4999    0\n",
       "5000    0\n",
       "Name: neg_count, Length: 5001, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_columns = [word for word in columns if word in negative_words]\n",
    "dtm_neg = dtm_df[neg_columns]\n",
    "\n",
    "dtm_neg['neg_count'] = dtm_neg.sum(axis=1)\n",
    "dtm_neg['neg_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.030303\n",
      "1       0.000000\n",
      "2       0.000000\n",
      "3       0.000000\n",
      "4       0.046512\n",
      "          ...   \n",
      "4996    0.000000\n",
      "4997    0.187500\n",
      "4998    0.095238\n",
      "4999    0.062500\n",
      "5000    0.178571\n",
      "Name: pos_proportion, Length: 5001, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-cafc0a53db4a>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dtm_pos['pos_proportion'] = dtm_pos['pos_count']/dtm_df.sum(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       0.026316\n",
       "1       0.000000\n",
       "2       0.000000\n",
       "3       0.000000\n",
       "4       0.039216\n",
       "          ...   \n",
       "4996    0.000000\n",
       "4997    0.176471\n",
       "4998    0.080000\n",
       "4999    0.055556\n",
       "5000    0.178571\n",
       "Name: pos_prop, Length: 5001, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_pos['pos_proportion'] = dtm_pos['pos_count']/dtm_df.sum(axis=1)\n",
    "print(dtm_pos['pos_proportion'])\n",
    "df['pos_prop']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Weighting dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll use a weighted dictionary to compare the relative average concreteness of the words used in Austen's *Pride and Prejudice* versus Alcott's *A Garland for Girls*. A weighted dictionary indicates not only whether a phrase is associated with a category, but *how strongly* it is associated with that category. In this approach, a dictionary is a list of weighted words.\n",
    "\n",
    "This could be done using a regular dictionary: a list of concrete and abstract words. Instead, we'll use a crowdsourced dictionary that provides an average \"concreteness score\" for a large number of English words.\n",
    "\n",
    "## 1.1 Read concreteness score dictionary\n",
    "\n",
    "First we'll create a pandas dataframe from the concreteness score dictionary, saved on our hard drive in the form of a .csv file.\n",
    "\n",
    "This dictionary comes from work by [Marc Brysbaert, Amy Beth Warriner, and Victor Kuperman.](https://link.springer.com/article/10.3758/s13428-013-0403-5) In summary:\n",
    "\n",
    "    The authors obtained Concreteness ratings for 37,058 English words and 2,896 two-word expressions (such as zebra crossing and zoom in), by means of a norming study using Internet crowdsourcing for data collection. They had over 4,000 participants rate 5 words on a concreteness scale, from 1 (very abstract) to 5 (very concrete). They define concrete words as words you can experience through the senses, and abstract words as words that you cannot experience through the senses. They provide the average concreteness score and the standard deviation for each word.\n",
    "\n",
    "Let's read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1.14</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1041179</td>\n",
       "      <td>Article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a cappella</td>\n",
       "      <td>1</td>\n",
       "      <td>2.92</td>\n",
       "      <td>1.44</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>Err:512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>0</td>\n",
       "      <td>4.68</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>21</td>\n",
       "      <td>Noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aback</td>\n",
       "      <td>0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.07</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>0.85</td>\n",
       "      <td>15</td>\n",
       "      <td>Adverb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abacus</td>\n",
       "      <td>0</td>\n",
       "      <td>4.52</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.93</td>\n",
       "      <td>12</td>\n",
       "      <td>Noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39949</th>\n",
       "      <td>zoom</td>\n",
       "      <td>0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>181</td>\n",
       "      <td>Verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39950</th>\n",
       "      <td>zoom in</td>\n",
       "      <td>1</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>Err:512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39951</th>\n",
       "      <td>zoom lens</td>\n",
       "      <td>1</td>\n",
       "      <td>4.81</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>Err:512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39952</th>\n",
       "      <td>zoophobia</td>\n",
       "      <td>0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.02</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>Err:512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39953</th>\n",
       "      <td>zucchini</td>\n",
       "      <td>0</td>\n",
       "      <td>4.87</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>49</td>\n",
       "      <td>Noun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39954 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  \\\n",
       "0               a       0    1.46     1.14        2     30           0.93   \n",
       "1      a cappella       1    2.92     1.44        3     29           0.90   \n",
       "2        aardvark       0    4.68     0.86        0     28           1.00   \n",
       "3           aback       0    1.65     1.07        4     27           0.85   \n",
       "4          abacus       0    4.52     1.12        2     29           0.93   \n",
       "...           ...     ...     ...      ...      ...    ...            ...   \n",
       "39949        zoom       0    3.10     1.49        0     30           1.00   \n",
       "39950     zoom in       1    3.57     1.40        0     28           1.00   \n",
       "39951   zoom lens       1    4.81     0.49        1     27           0.96   \n",
       "39952   zoophobia       0    2.04     1.02        2     25           0.92   \n",
       "39953    zucchini       0    4.87     0.57        0     30           1.00   \n",
       "\n",
       "       SUBTLEX  Dom_Pos  \n",
       "0      1041179  Article  \n",
       "1            0  Err:512  \n",
       "2           21     Noun  \n",
       "3           15   Adverb  \n",
       "4           12     Noun  \n",
       "...        ...      ...  \n",
       "39949      181     Verb  \n",
       "39950        0  Err:512  \n",
       "39951        0  Err:512  \n",
       "39952        0  Err:512  \n",
       "39953       49     Noun  \n",
       "\n",
       "[39954 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "con_score = pandas.read_csv('../day-2/data/Concreteness_ratings_Brysbaert_et_al.csv')\n",
    "con_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the most concrete and most abstract words by sorting on `Conc.M`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Conc.M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>bat</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10689</th>\n",
       "      <td>eagle</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30740</th>\n",
       "      <td>shawl</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36046</th>\n",
       "      <td>umbrella</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>basket</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39703</th>\n",
       "      <td>would</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32378</th>\n",
       "      <td>spirituality</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>although</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10905</th>\n",
       "      <td>eh</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11618</th>\n",
       "      <td>essentialness</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39954 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word  Conc.M\n",
       "2547             bat    5.00\n",
       "10689          eagle    5.00\n",
       "30740          shawl    5.00\n",
       "36046       umbrella    5.00\n",
       "2526          basket    5.00\n",
       "...              ...     ...\n",
       "39703          would    1.12\n",
       "32378   spirituality    1.07\n",
       "941         although    1.07\n",
       "10905             eh    1.04\n",
       "11618  essentialness    1.04\n",
       "\n",
       "[39954 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_score[['Word','Conc.M']].sort_values(by='Conc.M',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Conc.M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10905</th>\n",
       "      <td>eh</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11618</th>\n",
       "      <td>essentialness</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32378</th>\n",
       "      <td>spirituality</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>although</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39703</th>\n",
       "      <td>would</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25452</th>\n",
       "      <td>pick-up truck</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6160</th>\n",
       "      <td>comb</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6476</th>\n",
       "      <td>computer mouse</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7132</th>\n",
       "      <td>cookie</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37017</th>\n",
       "      <td>unicycle</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39954 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Word  Conc.M\n",
       "10905              eh    1.04\n",
       "11618   essentialness    1.04\n",
       "32378    spirituality    1.07\n",
       "941          although    1.07\n",
       "39703           would    1.12\n",
       "...               ...     ...\n",
       "25452   pick-up truck    5.00\n",
       "6160             comb    5.00\n",
       "6476   computer mouse    5.00\n",
       "7132           cookie    5.00\n",
       "37017        unicycle    5.00\n",
       "\n",
       "[39954 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_score[['Word','Conc.M']].sort_values(by='Conc.M',ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Merging a DTM with a weighted dictionary\n",
    "\n",
    "The goal is to merge this score with our document term matrix, so we can calculate the average concreteness score for our texts.\n",
    "\n",
    "To do this, we'll first create the DTM from our two novels, transpose this matrix, and merge it with the dataframe created above. We'll merge on the column 'Word'.\n",
    "\n",
    "First, create the DTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>1500</th>\n",
       "      <th>15th</th>\n",
       "      <th>1813</th>\n",
       "      <th>1887</th>\n",
       "      <th>18th</th>\n",
       "      <th>20</th>\n",
       "      <th>2001</th>\n",
       "      <th>26th</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younge</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youngsters</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "      <th>youths</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 9901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  1500  15th  1813  1887  18th  20  2001  26th  30  ...  york  young  \\\n",
       "0    0     0     1     2     0     1   0     0     1   0  ...     1    129   \n",
       "1    1     1     1     0     2     0   1     1     0   1  ...     2    109   \n",
       "\n",
       "   younge  younger  youngest  youngsters  youth  youthful  youths  zip  \n",
       "0       4       29        14           0      9         0       1    0  \n",
       "1       0        7         2           1      9         1       3    1  \n",
       "\n",
       "[2 rows x 9901 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = []\n",
    "#open and read the novels, save them as variables\n",
    "austen_string = open('../day-2/data/Austen_PrideAndPrejudice.txt', encoding='utf-8').read()\n",
    "alcott_string = open('../day-2/data/Alcott_GarlandForGirls.txt', encoding='utf-8').read()\n",
    "\n",
    "#append each novel to the list\n",
    "text_list.append(austen_string)\n",
    "text_list.append(alcott_string)\n",
    "\n",
    "countvec = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "novels_df = pandas.DataFrame(countvec.fit_transform(text_list).toarray(), columns=countvec.get_feature_names())\n",
    "novels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll take a subset of the DTM, keeping only the intersection between the words in our corpus and the word in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=list(novels_df)\n",
    "columns_con = [word for word in columns if word in list(con_score['Word'])]\n",
    "columns_con[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novels_df_con = novels_df[columns_con]\n",
    "novels_df_con "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, transpose the matrix, rename the column, and merge with the dictionary dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = novels_df_con.transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={0: 'Austen', 1: 'Alcott'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the index 'Word', and reset the index, so the words become a column in our dataframe and we get a new index.\n",
    "df.index.names = ['Word']\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with our dictionary dataframe, called 'con_score'\n",
    "df = df.merge(con_score, on = 'Word')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Weighting term frequencies by the concreteness score\n",
    "\n",
    "Now we can weight the term frquency cells by the concreteness score, by multiplying the frequency count column by the concreteness score column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['austen_con_score'] = df['Austen'] * df['Conc.M']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alcott_con_score'] = df['Alcott'] * df['Conc.M']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Calculate and print the average concreteness score for each text. Careful! Think through this before you implement it. You want the average score, normalized over all the words in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we'll devide the sum of the concreteness score by the total word count for each novel\n",
    "print(\"Mean Concreteness for Austen's 'Pride and Prejudice'\")\n",
    "print(df['austen_con_score'].sum()/df['Austen'].sum())\n",
    "print()\n",
    "print(\"Mean Concreteness for Alcott's 'A Garland for Girls'\")\n",
    "print(df['alcott_con_score'].sum()/df['Alcott'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Assessing the difference\n",
    "\n",
    "So there is a difference, but what does it mean? What is the magnitude of the difference?\n",
    "\n",
    "We can look at the difference between the two means as a percent difference based on the scale range. We can calculate this using simple math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first find the difference between the means by substracting one from the other\n",
    "3.1534507874-2.78328905828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the range of concreteness scores\n",
    "print(df['Conc.M'].min())\n",
    "print(df['Conc.M'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The scale range\n",
    "df['Conc.M'].max() - df['Conc.M'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the difference of means as a percent of this range\n",
    "(0.37/3.83)* 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "Print the most concrete and abstract terms in Austen and in Alcott.  \n",
    "*Hint:* You can't simply sort on the column `austen_con_score` and so on. Why not? What are your next steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe that keeps only words that have a non-zero value in Alcott\n",
    "df_alcott = df[df['Alcott']>0]\n",
    "#Sort on 'Conc.M' and pring in descending order for most concrete words\n",
    "df_alcott[['Word', 'Conc.M', 'Alcott']].sort_values(by=['Conc.M', 'Alcott'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe that keeps only words that have a non-zero value in Austen\n",
    "df_austen = df[df['Austen']>0]\n",
    "df_austen[['Word', 'Conc.M', 'Austen']].sort_values(by=['Conc.M', 'Austen'], ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
